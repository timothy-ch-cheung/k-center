\textcite{feo_greedy_1995} introduced an algorithm framework GRASP (Greedy Randomised Adaptive Search Procedures), which has been widely cited in combinatorial optimization literature. The main idea of GRASP is to perform three steps iteratively until some stopping criterion is met; first construct a randomised solution, optimise it using local search, and update the solution if it is better than the best so far. The pseudocode presented by \textcite{feo_greedy_1995} is shown in \cref{alg:grasp}.

\input{algorithms/grasp}

\textcite{mladenovic_solving_2003} introduced the concept of a \emph{critical vertex}; a vertex $v$ is a \emph{critical vertex} if and only if $d(v, min_{c\in C}d(v, c))=Cost(C)$, that is $v$ is a point which defines the cost of the solution $C$. \textcite{battiti_new_2017} extended this concept by counting the number of \emph{critical vertices} in a solution. Their work resulted in two algorithms to be embedded in the GRASP framework: the first constructs an inital randomised solution (\cref{alg:greedy_construction}) and a the other is a local search based on the \emph{critical vertices} concept (\cref{alg:plateau_surfer_local_search}). They local search cycles through different solutions with equal costs in order to escape local minima. They concluded that other local search methods would reach a plateau at a local minima and terminate the search, whereas their method could escape minima by progressively moving to solutions with fewer \emph{critical vertices}.

The Greedy Randomised Build (\cref{alg:greedy_construction}) first selects a set initial centers (lines 2-7), the number of centers to select is specified by the parameter $\alpha$ ($\alpha\in [0, 1]$); a higher $\alpha$ creates more randomised intial solutions and a lower alpha creates intial solutions which are greedier. Once the initial solution is created, the remaining $k-|C|$ centers are selected pseudo-greedily (lines 8-23). At each for loop at lines 11-18, an lower bound $z_{min}$ and upper bound $z_{max}$ is constructed. These lower/upper bounds are combined with a parameter $\beta$ ($\beta\in [0, 1]$) to construct the Restricted Candidate List (RCL) at line 20; the RCL is a list of the best centers to add to the current solution. The parameter $\beta$ controls the greediness; a higher $\beta$ allows centers of higher cost to be introduced to the solution (note that $\beta=0$ makes the selection at line 20 completely greedy). The time complexity is $\mathcal{O}(nk)$, since the worst case is when we have to build $k$ Restricted Candidate Lists.  

It is important to distinguish between the solution construction algorithms described in this section and the PBS algorithm (\cref{section:pbs}), PBS constructs initial solutions in a purely greedy manner whereas Greedy Randomised Build parameterises the greediness using $\alpha$ and $\beta$. \textcite{battiti_new_2017} did not report the values of $\alpha$ and $\beta$ they used to produce their results, we conducted experiments and determined that $\alpha =x$ and $\beta =y$ were suitable (our methodology is described in \cref{appendix:grasp_param}).

\input{algorithms/greedy_randomised_build}

Given an initial solution, the Plateau Surfer search (\cref{alg:plateau_surfer_local_search}) locally optimises it. To understand how the search works, we explicitly define the function CountCV (\cref{alg:count_cv}).

\input{algorithms/count_cv}

CountCV counts the number of \emph{critical vertices} of a given solution $C$ with cost $r$. A naive implemention of CountCV would have $\mathcal{O}(kn)$ time complexity, but we can use the neighbourhood structures defined by \textcite{mladenovic_solving_2003} we can reduce the time complexity to $\mathcal{O}(n)$ (detailed in \cref{section:pbs}). The Plateau Surfer local search (\cref{alg:plateau_surfer_local_search}) loops over every center $v_i$ in the current solution $C$ (lines 4-26) exchanging each center with every other vertex not currently in the solution (lines 9-18). At the end of the loop between lines 9-18, we may find a swap $v_j$ which either creates a solution with a lower cost ($v_j=$best\_flip) or creates a solution with equal cost but fewer \emph{critical vertices} ($v_j=$best\_cv\_flip). If such swap is found then we have not reached a minima, therefore we set \emph{modified} to true to continue the swapping phase, otherwise the search terminates. This algorithm is shown in \cref{alg:plateau_surfer_local_search} (we correct a typo from the original paper in line 8 , which initalised best\_cv with $\bar{C}$ instead of $C$). The time complexity is $\mathcal{O}(kn^2)$ (\cite{battiti_new_2017}).

\input{algorithms/plateau_surfer_local_search}

The key finding that \textcite{battiti_new_2017} made given a solution with two equal costs, the one with fewer \emph{critical vertices} is better. In their analysis, they reported better results than VNS (embedded in GRASP). However, we believe \textcite{battiti_new_2017} made an error in implementing the VNS algorithm; there are two reasons for this:
\begin{enumerate}
    \item \textcite{mladenovic_solving_2003} stated VNS should "always move to a
solution of equal value" but \textcite{battiti_new_2017} contradicts this, stating "as soon as a plateau is met, Mladenovi\'{c}â€™s local search ends"
    \item The VNS (embedded in GRASP) results (\cite{battiti_new_2017}) shows poorer performance than the original VNS results (\cite{mladenovic_solving_2003})
\end{enumerate}

We attempted to contact \textcite{battiti_new_2017} via email to verify this, but we did not receive a reply. Nevertheless their contribution remains valuable as it defines a systematic method for searching solutions of equal cost.