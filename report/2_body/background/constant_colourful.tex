\textcite{bandyapadhyay_constant_2019} devised a pseudo 2-approximation algorithm which produces a solution using at most $k+1$ centers. They also created a second procedure which exploited some geometric properties of the colourful $k$-center problem to deal with special cases where the centers are very far apart, which combined with the pseudo 2-approximation to produce a $(17+\epsilon)$ true approximation. However the geometric procedure is limited to a 2D Euclidean space, due to this limitation we focus only on the pseudo 2-approximation algorithm. For the remainder of this paper we refer to the pseudo 2-approximation as the \emph{Ban} algorithm for conciseness.

The \emph{Ban} algorithm is comprised of three components, two linear programs (LP1 and LP2) and a greedy clustering algorithm. We assume the reader has a basic understanding of linear programming, however for the uninitiated we include a short introduction in \cref{appendix:lp_intro}.

LP1 decides whether an instance of the colourful $k$-center problem can be solved with a cost $\rho$. To understand LP1, we need to define the concept of a \emph{ball} around point $j$ of radius $\rho$; the \emph{ball} $B(j,\rho)$ is the set of all points within $r$ distance of the point $j$. The decision variables for LP1 are $x$ and $z$, both of which can be fractional. Given a vertex $i\in V$, $x_i$ represents the degree that $i$ is a center and $z_i$ represents the degree that $i$ is covered by a center. For example, if $z_i=0$ then $i$ is not covered by any center and is therefore an outlier. If $x_i=1$, $i$ should be opened as a center. Constraints $(3)$ and $(4)$ of LP1 ensure that the solution covers at least $r$ and $b$ points respectively. LP1 is used to determine the optimal cost out of $n^2$ interpoint distances.

%TC:ignore
\centerline{\begin{minipage}{0.8\textwidth}
    \vspace{0.5cm}
    \input{algorithms/constant_colourful/LP1}
\end{minipage}}
%TC:endignore

The greedy clustering algorithm (\cref{alg:greedy_cluster_lp}) clusters the $V$ into $|O|$ clusters with centers $C$ and creates a set of updated decision variables $(\tilde{x},\tilde{z})$ from the LP1 solution $(x,z)$ which shifts the $x_i$ value ($i\in B(j,\rho$) to its center $\tilde{x_j}$ (\cref{alg:greedy_cluster_lp} lines 7,10-13).

\input{algorithms/constant_colourful/greedy_clustering}

Given clusters $O$ which contain vertices at most $2\rho$ distance away from their center, if we can pick $k$ clusters from $O$ which meet the blue/red constraints then we have a 2-approximation. \citeauthor{bandyapadhyay_constant_2019} proved while it is not always possible to select $k$ clusters which satisfy the constraints, it is always possible to select $k+1$ clusters. They formalised this procedure in LP2 which maximises the coverage of red vertices $r_i$ using centers $\tilde{x_i}$, constrained to covering at least $b$ blue vertices using $\leq k$ centers. They reported that there can be at most two fractional values for $\tilde{x_i}$, therefore they can both be rounded up for solution with at most $k+1$ centers.

%TC:ignore
\centerline{\begin{minipage}{0.8\textwidth}
    \vspace{0.5cm}
    \input{algorithms/constant_colourful/LP2}
\end{minipage}}
%TC:endignore

As their research takes a purely theoretical viewpoint, they assume $\rho$ from LP1 is 'guessed' correctly, hence $\rho=OPT$. However from a practical viewpoint, there are $n^2$ candidate costs ; a na\"{i}ve implementation would need $\mathcal{O}(n^2)$ calls to LP1. In our testing, each call to LP1 is time consuming. We show a practical implementation of the pseudo-approximation algorithm, based on a binary search, which makes $\mathcal{O}(log_2 n)$ calls to LP1.

\input{algorithms/constant_colourful/solve_colourful}

Analysing the complexity is slightly more involved as we use \acrshort{lp}s. The simplex method, developed by George Dantzig in 1947 (\cite{dantzig_origins_1990}), is popular technique to solve \acrshort{lp}s; the worse case time complexity is $\mathcal{O}(2^n)$ \parencites{klee_simplex_1972}[Chapter~5.9]{matousek_understanding_2007}. However in general this is not an issue, since the simplex algorithm has polynomial \emph{smoothed complexity} (\cite{spielman_smoothed_2001}). \emph{Smoothed complexity} combines worse case and average case complexity with slight random perturbations of the inputs which provides a more practical measure of performance. Therefore the \emph{smoothed complexity} of the \emph{Ban} algorithm is $n^{\mathcal{O}(1)}$.