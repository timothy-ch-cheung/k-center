The problem setting for the $k$-center problem  is an undirected weighted graph $G=(V,E)$ on $n$ vertices. The weight of an edge between two vertices $v_1, v_2$ is given by a function $dist(v_1,v_2)\rightarrow\mathbb{R}_{\ge 0}$. The distance function must satisfy triangular inequality; the sum of any two sides of a triangle is less than or equal to the length of the remaing side. In the context of graphs, given any three vertices the following holds for any pair of vertices: \(dist(a,b) \leq dist(a, c) + dist(b, c) \).

\textcite{hakimi_optimum_1964} first introduced two problems: the absolute center and the vertex center of a weighted undirected graph. The absolute center considers any point $x$ on an edge and therefore defines a more general distance metric between two points along any two edges; this metric is given by a function $pdist(x_1,x_2)\rightarrow\mathbb{R}_{\ge 0}$ which is the sum of the path between the two points (since a point can lie inbetween an edge, the path can contain a partial edge). The goal is to find a point $c$ which minimises the maximum $pdist(c,x_i)$ for all points along the edges. In contrast the vertex center restricts the center candidates to vertices in $G$. Therefore the goal is to find a vertex $c$ which minimises the maximum $dist(c, v_i)$ for all vertices $v_i\in V$. It should be noted that in the remainder of this paper, when we refer to center type problems, we are referring to the vertex center rather than the absolute center. 

\textcite{hakimi_optimum_1965} published further work one year later which generalised the absolute and vertex center problems, by considering the allocation of $k$ centers rather than a single center; the original problem definition can be thought of as the 1-center problem. The $k$-center problem can be thought of as a facility location problem, where we want to locate $k$ facilities in order to best service the $n$ clients. The clients $N$ and potential location for facilities $M$ are subsets of the vertices, such that $N\subseteq V$ and $M\subseteq V$. We consider the scenario where every vertex can either be a client or a facility, where $M=N=V$. The $k$-center problem can therefore be defined more formally as follows:

\textbox{Given a graph $G=(V, E)$ on a set of $n$ vertices $V = \{v_1,..., v_n\}$ and a parameter $k$ specifying the maximum number of centers (where $1\leq k\leq n$): 

\vspace{0.2cm}We want to find a subset of centers $C\subseteq V$ such that $|C|\leq k$ which minimises the objective function: $max_{v\in V}min_{c\in C}dist(v, c)$}

An alternative way to describe this problem would be to imagine a city where we would like to build warehouses for a parcel delivery service. Given a destination for a parcel, the parcel will depart from the warehouse nearest to the destination. The city would like to build these warehouses in the optimal locations such that the largest distance a delivery driver will have to travel is minimised. Now consider that the city has a limited budget and they can only build \(k\) warehouses. In this scenario, we want to allocate $k$ warehouses to minimise the distance between the house that is furthest away from its nearest warehouse.

Later work showed that while solving the vertex 1-center problem is a trivial process, solving the $k$-center problem for graphs of arbitrary structure is NP-hard (\cite{kariv_algorithmic_1979}). Their worked focused on a simplified version of the $k$-center problem, where the graph has a tree structure. A graph with a tree structure is defined as a connected graph where any two vertices are connected by exactly one path. \textcite{kariv_algorithmic_1979} reported a $\mathcal{O}(n^2\cdot log(n))$ algorithm which solves the $k$-center problem on trees.

Given the NP-hardness of the $k$-center problem, there exists no algorithm with gives an optimal solution which also runs in polynomial time. Therefore when designing algorithms for NP-hard problems, we either aim to give an optimal solution in exponential time or a non-optimal solutions in polynomial time. Throughout this paper, when we refer to a solution for the $k$-center problem (and its variants) we are referring to a valid solution which may or may not have the optimal cost. In the literature for the $k$-center problem, the latter forms the majority of the studies. The primary algorithm paradigms applied to the $k$-center problem include approximation algorithms, randomized algorithms, metaheuristics and local search techniques. We define these paradigms below:
\begin{itemize}
    \item \textbf{Approximation algorithms}: a type of algorithm that returns a solution with a provable guarantee to be within a certain distance to the optimal solution. The guarantee is expressed as a multiplicative factor, for example a $n$-approximation algorithm will always return a solution equal to or less than $n$ times the cost of the optimal solution. Another common notation used is a $\mathcal{O}(1)$-approximation, which does not define a specific approximation factor but states that the approximation factor does not grow with the size of the input. 
    \item \textbf{Heuristic}: a "rule of thumb" strategy for solving a problem which aims to lead to a good solution. The strategy is problem dependent.
    \item \textbf{Metaheuristics}: a higher level strategy for solving a problem which is independent of the problem it is trying to solve, which serves as a framework for designing heuristics.
    \item \textbf{Local search}: a metaheuristic where we are given a candidate solution, and our search space are neighbours of the candidate solution; the objective of the search is to find a neighbour solution better solution than the original candidate.
    \item \textbf{Randomized algorithms}: a type of algorithm which relies on randomness to make decisions; typically the aim is to use randomness to reduce the the time complexity of the algorithm.
    \item \textbf{Genetic algorithms}: a type of algorithm inspired by natural selection, it maintains a population which is used to create offspring for the next generation.
\end{itemize}

Several approximation algorithms have been proposed to solve the $k$-center problem, the most widely cited are is the \emph{Gon} algorithm (\cite{gonzalez_clustering_1985}) and the \emph{HS} algorithm (\cite{hochbaum_best_1985}) which both produce 2-approximations; they are described in detail in \cref{section:greedy}. The \emph{Gon} algorithm is based on a greedy heuristic and the \emph{HS} is based on a binary search. Furthermore, \textcite{hochbaum_best_1985} proved that the $k$-center problem is not only NP-hard to solve optimally, but it is also NP-hard to approximate to for any approximation factor less than 2.

One of the more influential metaheuristics for combinatorial optimisation is VNS (Variable Neighbourhood Search), first introduced by \textcite{mladenovic_variable_1997}. The basic concept of VNS is to use local search to explore the current neighbourhood of solutions, and to switch neighbourhood if better solutions than the incumbent is found. The VNS metaheuristic was later applied to the $k$-center problem by \textcite{mladenovic_solving_2003}. Given an incumbent solution $C$, the neighbourhood structure is defined as solution $C$ with each facility replaced by every other potential facility making the cardinality of $N(C)$ equal $k\times (n-k)$. To efficiently implement this, data structures were designed to store, for each client, the closest and second closest facility to it. Their application of the VNS metaheuristic resulted in a $\mathcal{O}(i\cdot n^{2})$, where $i$ is the number of VNS iterations. \textcite{mladenovic_solving_2003} evaluated their algorithm on the OR-LIB problem instances, a standard data set originally used for $k$-median problems (\cite{beasley_note_1985}) later adapted for the $k$-center. Their empirical results showed that the VNS algorithm significantly outperformed the \emph{Gon} and \emph{HS} approximation algorithms.

Later publications built upon the VNS algorithm, the neighbourhood structures created by \textcite{mladenovic_solving_2003} were used in the PBS (Population Based Search) algorithm (\cite{pullan_memetic_2008}). PBS is a metaheuristic which aims to generate starting points to run local search on. To do this it uses a memetic algorithm, an extension of a genetic algorithm which conducts a local search on the individuals of the population. Their work showed the ability to converge to the optimal cost in the OR-LIB data set where VNS could not.

To the best of our knowledge, the most recent literature using search based techniques proposed for solving the standard $k$-center problem is the Plateau Surfer algorithm (\cite{battiti_new_2017}). Their work builds upon the observations by \textcite{mladenovic_solving_2003} of $k$-center solutions which have equal cost but different vertices forming the furthest vertex from its nearest center. They observed that these solutions of equal cost could trap the search in a local minima, and proposed algorithms to escape these minima. They reported that their algorithm produced near optimal solutions faster than state of the art local search techniques for the $k$-center.

While both the PBS (\cite{pullan_memetic_2008}) and Plateau Surfer algorithm (\cite{battiti_new_2017}) were reported to have better performance than VNS (\cite{mladenovic_solving_2003}), \textcite{battiti_new_2017} did not compare the PBS algorithm to their Plateau surfer algorithm; in our study we will implement both and compare their performance. The PBS and the Plateau Surfer algorithms are discussed in further detail in \cref{section:pbs} and \cref{section:plateau_surfer} respectively.