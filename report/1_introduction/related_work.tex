As identified by \textcite{anegg_technique_2020}, most of the generalisations of the $k$-center problem fall under one of two categories:
\begin{itemize}
    \item constraints on which points can be selected as centers
    \item constraints on the points which must be covered
\end{itemize}

An example of the former is the fair $k$-center (\cite{kleindessner_fair_2019}), the clients are split into demographic groups (similarly to the colorful $k$-center), and a constraint on the number of centers which can be chosen from each group is introduced.

 An example of the latter is the colourful $k$-center. The Fair Robust $k$-center (\cite{harris_lottery_2017}) is another example of the latter, it highlighted that the robust $k$-center problem could be biased towards always excluding the same outliers. The Fair Robust $k$-center uses a lottery model which adds individual probabilities that a given vertex will be covered. Their results showed a pseudo approximation which opened at most $k+1$ centers, which was later improved upon by \citeauthor{anegg_technique_2020} to a true 4-approximation.

The notion of fairness in the wider field of machine learning (\acrshort{ml}) has been well established; \textcite{mehrabi_survey_2019} conducted a comprehensive review of bias in \acrshort{ml}. Their work covered real world cases where \acrshort{ml} had been unfairly biased, with a detailed breakdown of different types of bias and an overview the algorithms proposed for fair \acrshort{ml}.