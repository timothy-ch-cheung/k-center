
@article{bandyapadhyay_constant_2019,
	title = {A Constant Approximation for Colorful k-Center},
	url = {http://arxiv.org/abs/1907.08906},
	abstract = {In this paper, we consider the colorful \$k\$-center problem, which is a generalization of the well-known \$k\$-center problem. Here, we are given red and blue points in a metric space, and a coverage requirement for each color. The goal is to find the smallest radius \${\textbackslash}rho\$, such that with \$k\$ balls of radius \${\textbackslash}rho\$, the desired number of points of each color can be covered. We obtain a constant approximation for this problem in the Euclidean plane. We obtain this result by combining a "pseudo-approximation" algorithm that works in any metric space, and an approximation algorithm that works for a special class of instances in the plane. The latter algorithm uses a novel connection to a certain matching problem in graphs.},
	journaltitle = {{arXiv}:1907.08906 [cs]},
	author = {Bandyapadhyay, Sayan and Inamdar, Tanmay and Pai, Shreyas and Varadarajan, Kasturi},
	urldate = {2020-10-12},
	date = {2019-07-20},
	eprinttype = {arxiv},
	eprint = {1907.08906},
	keywords = {Computer Science - Computational Geometry, Computer Science - Data Structures and Algorithms, high, viewed},
	file = {arXiv.org Snapshot:C\:\\Users\\timch\\Zotero\\storage\\QTMXZB9V\\1907.html:text/html;arXiv Fulltext PDF:C\:\\Users\\timch\\Zotero\\storage\\6LSAQ2GN\\Bandyapadhyay et al. - 2019 - A Constant Approximation for Colorful k-Center.pdf:application/pdf},
}

@article{hakimi_optimum_1964,
	title = {Optimum Locations of Switching Centers and the Absolute Centers and Medians of a Graph},
	volume = {12},
	issn = {0030-364X},
	url = {https://doi.org/10.1287/opre.12.3.450},
	doi = {10.1287/opre.12.3.450},
	abstract = {The concepts of the "center" and the "median vertex" of a graph are generalized to the "absolute center" and the "absolute median" of a weighted graph a graph with weights attached to its vertices as well as to its branches. These results are used to find the optimum location of a "switching center" in a communication network and to locate the best place to build a "police station" in a highway system. It is shown that the optimum location of a switching center is always at a vertex of the communication network while the best location for the police station is not necessarily at an intersection. Procedures for finding these locations are given.},
	pages = {450--459},
	number = {3},
	journaltitle = {Operations Research},
	shortjournal = {Oper. Res.},
	author = {Hakimi, S. L.},
	urldate = {2021-02-21},
	date = {1964-06-01},
}

@article{kariv_algorithmic_1979,
	title = {An Algorithmic Approach to Network Location Problems. I: The p-Centers},
	volume = {37},
	issn = {0036-1399},
	url = {https://www.jstor.org/stable/2100910},
	shorttitle = {An Algorithmic Approach to Network Location Problems. I},
	abstract = {Problems of finding p-centers and dominating sets of radius r in networks are discussed in this paper. Let n be the number of vertices and {\textbar}E{\textbar} be the number of edges of a network. With the assumption that the distance-matrix of the network is available, we design an \$O({\textbar}E{\textbar} {\textbackslash}cdot n {\textbackslash}cdot {\textbackslash}lg n)\$ algorithm for finding an absolute 1-center of a vertex-weighted network and an \$O({\textbar}E{\textbar} {\textbackslash}cdot n + n{\textasciicircum}2 {\textbackslash}cdot {\textbackslash}lg n)\$ algorithm for finding an absolute 1-center of a vertex-unweighted network (the problem of finding a vertex 1-center of a network is trivial). We show that the problem of finding a (vertex or absolute) p-center (for \$1 {\textless} p {\textless} n)\$ of a (vertex-weighted or vertex-unweighted) network, and the problem of finding a dominating set of radius r are {NP}-hard even in the case where the network has a simple structure (e.g., a planar graph of maximum vertex degree 3). However, we describe an algorithm of complexity \$O {\textbackslash}lbrack ({\textbar}E{\textbar}{\textasciicircum}p {\textbackslash}cdot n{\textasciicircum}\{2p - 1\}/(p - 1)!) {\textbackslash}lg n {\textbackslash}rbrack\$ (respectively, O [ {\textbar}E{\textbar}p · n2p - 1/(p - 1)! ]) for finding an absolute p-center in a vertex-weighted (respectively, vertex-unweighted) network. We proceed by discussing the problems of finding p-centers and dominating sets of networks whose underlying graphs are trees. When the network is a vertex-weighted tree, we obtain the following algorithms: An \$O(n {\textbackslash}cdot {\textbackslash}lg n)\$ algorithm for finding the (vertex or absolute) 1-center; an O(n) algorithm for finding a (vertex or absolute) dominating set of radius r; an \$O(n{\textasciicircum}2 {\textbackslash}cdot {\textbackslash}lg n)\$ algorithm for finding a (vertex or absolute) p-center for any \$1 {\textless} p {\textless} n\$. Some generalizations of these problems are discussed. When the network is a vertex-unweighted tree, O(n) algorithms for finding the (vertex or absolute) 1-center and an absolute 2-center are already known; we extend these results by giving an \$O(n {\textbackslash}cdot {\textbackslash}lg{\textasciicircum}\{p - 2\} n)\$ algorithm for finding an absolute p-center (where \$3 {\textbackslash}leqq p {\textless} n)\$ and an \$O(n {\textbackslash}cdot {\textbackslash}lg{\textasciicircum}\{p - 1\} n)\$ algorithm for finding a vertex p-center (where \$2 {\textbackslash}leqq p {\textless} n)\$. In part {II} we treat the p-median problem.},
	pages = {513--538},
	number = {3},
	journaltitle = {{SIAM} Journal on Applied Mathematics},
	author = {Kariv, O. and Hakimi, S. L.},
	urldate = {2021-02-21},
	date = {1979},
	note = {Publisher: Society for Industrial and Applied Mathematics},
}

@inproceedings{charikar_algorithms_2001,
	title = {Algorithms for facility location problems with outliers},
	doi = {10.1145/365411.365555},
	abstract = {Facility location problems are traditionally investigated with the assumption that all the clients are to be provided service. A significant shortcoming of this formulation is that a few very distant clients, called outliers, can exert a disproportionately strong influence over the final solution. In this paper we explore a generalization of various facility location problems (K-center, K-median, uncapacitated facility location etc) to the case when only a specified fraction of the customers are to be served. What makes the problems harder is that we have to also select the subset that should get service. We provide generalizations of various approximation algorithms to deal with this added constraint.},
	eventtitle = {Proceedings of {SODA}},
	pages = {642--651},
	author = {Charikar, Moses and Khuller, Samir and Mount, David and Narasimhan, Giri},
	date = {2001-01-01},
	file = {Full Text PDF:C\:\\Users\\timch\\Zotero\\storage\\92TTFV9F\\Charikar et al. - 2001 - Algorithms for facility location problems with out.pdf:application/pdf},
}

@article{obermeyer_predicting_2016,
	title = {Predicting the Future — Big Data, Machine Learning, and Clinical Medicine},
	volume = {375},
	issn = {0028-4793},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5070532/},
	doi = {10.1056/NEJMp1606181},
	pages = {1216--1219},
	number = {13},
	journaltitle = {The New England journal of medicine},
	shortjournal = {N Engl J Med},
	author = {Obermeyer, Ziad and Emanuel, Ezekiel J.},
	urldate = {2021-02-28},
	date = {2016-09-29},
	pmid = {27682033},
	pmcid = {PMC5070532},
	file = {PubMed Central Full Text PDF:C\:\\Users\\timch\\Zotero\\storage\\I3T24SX4\\Obermeyer and Emanuel - 2016 - Predicting the Future — Big Data, Machine Learning.pdf:application/pdf},
}

@book{zhao_parallel_1970,
	title = {Parallel K-Means Clustering Based on {MapReduce}},
	volume = {5931},
	isbn = {978-3-642-10664-4},
	abstract = {Data clustering has been received considerable attention in many applications, such as data mining, document retrieval, image
segmentation and pattern classification. The enlarging volumes of information emerging by the progress of technology, makes
clustering of very large scale of data a challenging task. In order to deal with the problem, many researchers try to design
efficient parallel clustering algorithms. In this paper, we propose a parallel k-means clustering algorithm based on {MapReduce}, which is a simple yet powerful parallel programming technique. The experimental
results demonstrate that the proposed algorithm can scale well and efficiently process large datasets on commodity hardware.},
	pagetotal = {674},
	author = {Zhao, Weizhong and Ma, Huifang and He, Qing},
	date = {1970-01-01},
	doi = {10.1007/978-3-642-10665-1_71},
	note = {Journal Abbreviation: Cloud computing
Pages: 679
Publication Title: Cloud computing},
}

@article{dean_mapreduce_2008,
	title = {{MapReduce}: simplified data processing on large clusters},
	volume = {51},
	issn = {0001-0782},
	url = {https://doi.org/10.1145/1327452.1327492},
	doi = {10.1145/1327452.1327492},
	shorttitle = {{MapReduce}},
	abstract = {{MapReduce} is a programming model and an associated implementation for processing and generating large datasets that is amenable to a broad variety of real-world tasks. Users specify the computation in terms of a map and a reduce function, and the underlying runtime system automatically parallelizes the computation across large-scale clusters of machines, handles machine failures, and schedules inter-machine communication to make efficient use of the network and disks. Programmers find the system easy to use: more than ten thousand distinct {MapReduce} programs have been implemented internally at Google over the past four years, and an average of one hundred thousand {MapReduce} jobs are executed on Google's clusters every day, processing a total of more than twenty petabytes of data per day.},
	pages = {107--113},
	number = {1},
	journaltitle = {Communications of the {ACM}},
	shortjournal = {Commun. {ACM}},
	author = {Dean, Jeffrey and Ghemawat, Sanjay},
	urldate = {2021-02-28},
	date = {2008-01-01},
}

@article{pullan_memetic_2008,
	title = {A Memetic Genetic Algorithm for the Vertex \textit{p} -center Problem},
	volume = {16},
	issn = {1063-6560, 1530-9304},
	url = {https://www.mitpressjournals.org/doi/abs/10.1162/evco.2008.16.3.417},
	doi = {10.1162/evco.2008.16.3.417},
	abstract = {The p-center problem is one of choosing p facilities from a set of candidates to satisfy the demands of n clients in order to minimize the maximum cost between a client and the facility to which it is assigned. In this article, {PBS}, a population based meta-heuristic for the p-center problem, is described. {PBS} is a genetic algorithm based meta-heuristic that uses phenotype crossover and directed mutation operators to generate new starting points for a local search. For larger p-center instances, {PBS} is able to effectively utilize a number of computer processors. It is shown empirically that {PBS} has comparable performance to state-of-the-art exact and approximate algorithms for a range of pcenter benchmark instances.},
	pages = {417--436},
	number = {3},
	journaltitle = {Evolutionary Computation},
	shortjournal = {Evolutionary Computation},
	author = {Pullan, Wayne},
	urldate = {2020-10-12},
	date = {2008-09},
	langid = {english},
	keywords = {viewed, high},
	file = {Pullan - 2008 - A Memetic Genetic Algorithm for the Vertex pi.pdf:C\:\\Users\\timch\\Zotero\\storage\\W2Z8564J\\Pullan - 2008 - A Memetic Genetic Algorithm for the Vertex pi.pdf:application/pdf},
}

@inproceedings{agarwal_structured_2003,
	location = {New York, {NY}, {USA}},
	title = {Structured importance sampling of environment maps},
	isbn = {978-1-58113-709-5},
	url = {https://doi.org/10.1145/1201775.882314},
	doi = {10.1145/1201775.882314},
	series = {{SIGGRAPH} '03},
	abstract = {We introduce structured importance sampling, a new technique for efficiently rendering scenes illuminated by distant natural illumination given in an environment map. Our method handles occlusion, high-frequency lighting, and is significantly faster than alternative methods based on Monte Carlo sampling. We achieve this speedup as a result of several ideas. First, we present a new metric for stratifying and sampling an environment map taking into account both the illumination intensity as well as the expected variance due to occlusion within the scene. We then present a novel hierarchical stratification algorithm that uses our metric to automatically stratify the environment map into regular strata. This approach enables a number of rendering optimizations, such as pre-integrating the illumination within each stratum to eliminate noise at the cost of adding bias, and sorting the strata to reduce the number of sample rays. We have rendered several scenes illuminated by natural lighting, and our results indicate that structured importance sampling is better than the best previous Monte Carlo techniques, requiring one to two orders of magnitude fewer samples for the same image quality.},
	pages = {605--612},
	booktitle = {{ACM} {SIGGRAPH} 2003 Papers},
	publisher = {Association for Computing Machinery},
	author = {Agarwal, Sameer and Ramamoorthi, Ravi and Belongie, Serge and Jensen, Henrik Wann},
	urldate = {2021-03-01},
	date = {2003-07-01},
	keywords = {environment mapping, global illumination, illumination, image synthesis, Monte Carlo techniques, ray tracing, rendering, shadow algorithms},
	file = {Full Text PDF:C\:\\Users\\timch\\Zotero\\storage\\C3MZIM6Q\\Agarwal et al. - 2003 - Structured importance sampling of environment maps.pdf:application/pdf},
}

@article{kleindessner_fair_2019,
	title = {Fair k-Center Clustering for Data Summarization},
	url = {http://arxiv.org/abs/1901.08628},
	abstract = {In data summarization we want to choose \$k\$ prototypes in order to summarize a data set. We study a setting where the data set comprises several demographic groups and we are restricted to choose \$k\_i\$ prototypes belonging to group \$i\$. A common approach to the problem without the fairness constraint is to optimize a centroid-based clustering objective such as \$k\$-center. A natural extension then is to incorporate the fairness constraint into the clustering problem. Existing algorithms for doing so run in time super-quadratic in the size of the data set, which is in contrast to the standard \$k\$-center problem being approximable in linear time. In this paper, we resolve this gap by providing a simple approximation algorithm for the \$k\$-center problem under the fairness constraint with running time linear in the size of the data set and \$k\$. If the number of demographic groups is small, the approximation guarantee of our algorithm only incurs a constant-factor overhead.},
	journaltitle = {{arXiv}:1901.08628 [cs, stat]},
	author = {Kleindessner, Matthäus and Awasthi, Pranjal and Morgenstern, Jamie},
	urldate = {2020-10-10},
	date = {2019-05-10},
	eprinttype = {arxiv},
	eprint = {1901.08628},
	keywords = {low, viewed, Computer Science - Data Structures and Algorithms, Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {arXiv.org Snapshot:C\:\\Users\\timch\\Zotero\\storage\\MB8ESKBZ\\1901.html:text/html;arXiv Fulltext PDF:C\:\\Users\\timch\\Zotero\\storage\\HDYASUVT\\Kleindessner et al. - 2019 - Fair k-Center Clustering for Data Summarization.pdf:application/pdf},
}

@article{do_sphetcher_2020,
	title = {Sphetcher: Spherical Thresholding Improves Sketching of Single-Cell Transcriptomic Heterogeneity},
	volume = {23},
	issn = {2589-0042},
	url = {https://www.sciencedirect.com/science/article/pii/S2589004220303114},
	doi = {10.1016/j.isci.2020.101126},
	shorttitle = {Sphetcher},
	abstract = {The massive size of single-cell {RNA} sequencing datasets often exceeds the capability of current computational analysis methods to solve routine tasks such as detection of cell types. Recently, geometric sketching was introduced as an alternative to uniform subsampling. It selects a subset of cells (the sketch) that evenly cover the transcriptomic space occupied by the original dataset, to accelerate downstream analyses and highlight rare cell types. Here, we propose algorithm Sphetcher that makes use of the thresholding technique to efficiently pick representative cells within spheres (as opposed to the typically used equal-sized boxes) that cover the entire transcriptomic space. We show that the spherical sketch computed by Sphetcher constitutes a more accurate representation of the original transcriptomic landscape. Our optimization scheme allows to include fairness aspects that can encode prior biological or experimental knowledge. We show how a fair sampling can inform the inference of the trajectory of human skeletal muscle myoblast differentiation.},
	pages = {101126},
	number = {6},
	journaltitle = {{iScience}},
	shortjournal = {{iScience}},
	author = {Do, Van Hoan and Elbassioni, Khaled and Canzar, Stefan},
	urldate = {2021-03-01},
	date = {2020-06-26},
	langid = {english},
	keywords = {Bioinformatics, Data Analysis, Transcriptomics},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\timch\\Zotero\\storage\\WP99ZVAG\\Do et al. - 2020 - Sphetcher Spherical Thresholding Improves Sketchi.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\timch\\Zotero\\storage\\YWEGD892\\S2589004220303114.html:text/html},
}

@article{anegg_technique_2020,
	title = {A Technique for Obtaining True Approximations for \$k\$-Center with Covering Constraints},
	url = {http://arxiv.org/abs/2007.03946},
	abstract = {There has been a recent surge of interest in incorporating fairness aspects into classical clustering problems. Two recently introduced variants of the \$k\$-Center problem in this spirit are Colorful \$k\$-Center, introduced by Bandyapadhyay, Inamdar, Pai, and Varadarajan, and lottery models, such as the Fair Robust \$k\$-Center problem introduced by Harris, Pensyl, Srinivasan, and Trinh. To address fairness aspects, these models, compared to traditional \$k\$-Center, include additional covering constraints. Prior approximation results for these models require to relax some of the normally hard constraints, like the number of centers to be opened or the involved covering constraints, and therefore, only obtain constant-factor pseudo-approximations. In this paper, we introduce a new approach to deal with such covering constraints that leads to (true) approximations, including a \$4\$-approximation for Colorful \$k\$-Center with constantly many colors---settling an open question raised by Bandyapadhyay, Inamdar, Pai, and Varadarajan---and a \$4\$-approximation for Fair Robust \$k\$-Center, for which the existence of a (true) constant-factor approximation was also open. We complement our results by showing that if one allows an unbounded number of colors, then Colorful \$k\$-Center admits no approximation algorithm with finite approximation guarantee, assuming that \${\textbackslash}mathrm\{P\} {\textbackslash}neq {\textbackslash}mathrm\{{NP}\}\$. Moreover, under the Exponential Time Hypothesis, the problem is inapproximable if the number of colors grows faster than logarithmic in the size of the ground set.},
	journaltitle = {{arXiv}:2007.03946 [cs, math]},
	author = {Anegg, Georg and Angelidakis, Haris and Kurpisz, Adam and Zenklusen, Rico},
	urldate = {2020-10-12},
	date = {2020-07-08},
	eprinttype = {arxiv},
	eprint = {2007.03946},
	keywords = {unread, Computer Science - Data Structures and Algorithms, 90C27, 68W40, 68Q25, 90C05, Mathematics - Optimization and Control},
	file = {arXiv.org Snapshot:C\:\\Users\\timch\\Zotero\\storage\\6GJ55JPL\\2007.html:text/html;arXiv Fulltext PDF:C\:\\Users\\timch\\Zotero\\storage\\9MQM3WPG\\Anegg et al. - 2020 - A Technique for Obtaining True Approximations for .pdf:application/pdf},
}

@article{harris_lottery_2017,
	title = {A Lottery Model for Center-type Problems With Outliers},
	url = {http://arxiv.org/abs/1710.00287},
	abstract = {In this paper, we give tight approximation algorithms for the \$k\$-center and matroid center problems with outliers. Unfairness arises naturally in this setting: certain clients could always be considered as outliers. To address this issue, we introduce a lottery model in which each client \$j\$ is allowed to submit a parameter \$p\_j {\textbackslash}in [0,1]\$ and we look for a random solution that covers every client \$j\$ with probability at least \$p\_j\$. Our techniques include a randomized rounding procedure to round a point inside a matroid intersection polytope to a basis plus at most one extra item such that all marginal probabilities are preserved and such that a certain linear function of the variables does not decrease in the process with probability one.},
	journaltitle = {{arXiv}:1710.00287 [cs]},
	author = {Harris, David G. and Pensyl, Thomas and Srinivasan, Aravind and Trinh, Khoa},
	urldate = {2021-03-01},
	date = {2017-09-30},
	eprinttype = {arxiv},
	eprint = {1710.00287},
	keywords = {Computer Science - Data Structures and Algorithms},
	file = {arXiv Fulltext PDF:C\:\\Users\\timch\\Zotero\\storage\\BSANCYZ9\\Harris et al. - 2017 - A Lottery Model for Center-type Problems With Outl.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\timch\\Zotero\\storage\\4NIHIJRR\\1710.html:text/html},
}

@article{mehrabi_survey_2019,
	title = {A Survey on Bias and Fairness in Machine Learning},
	url = {http://arxiv.org/abs/1908.09635},
	abstract = {With the widespread use of {AI} systems and applications in our everyday lives, it is important to take fairness issues into consideration while designing and engineering these types of systems. Such systems can be used in many sensitive environments to make important and life-changing decisions; thus, it is crucial to ensure that the decisions do not reflect discriminatory behavior toward certain groups or populations. We have recently seen work in machine learning, natural language processing, and deep learning that addresses such challenges in different subdomains. With the commercialization of these systems, researchers are becoming aware of the biases that these applications can contain and have attempted to address them. In this survey we investigated different real-world applications that have shown biases in various ways, and we listed different sources of biases that can affect {AI} applications. We then created a taxonomy for fairness definitions that machine learning researchers have defined in order to avoid the existing bias in {AI} systems. In addition to that, we examined different domains and subdomains in {AI} showing what researchers have observed with regard to unfair outcomes in the state-of-the-art methods and how they have tried to address them. There are still many future directions and solutions that can be taken to mitigate the problem of bias in {AI} systems. We are hoping that this survey will motivate researchers to tackle these issues in the near future by observing existing work in their respective fields.},
	journaltitle = {{arXiv}:1908.09635 [cs]},
	author = {Mehrabi, Ninareh and Morstatter, Fred and Saxena, Nripsuta and Lerman, Kristina and Galstyan, Aram},
	urldate = {2021-03-02},
	date = {2019-09-17},
	eprinttype = {arxiv},
	eprint = {1908.09635},
	keywords = {Computer Science - Machine Learning},
	file = {arXiv Fulltext PDF:C\:\\Users\\timch\\Zotero\\storage\\9J86WV33\\Mehrabi et al. - 2019 - A Survey on Bias and Fairness in Machine Learning.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\timch\\Zotero\\storage\\KIAHBP7Z\\1908.html:text/html},
}

@article{gonzalez_clustering_1985,
	title = {Clustering to minimize the maximum intercluster distance},
	volume = {38},
	issn = {03043975},
	url = {https://linkinghub.elsevier.com/retrieve/pii/0304397585902245},
	doi = {10.1016/0304-3975(85)90224-5},
	abstract = {The problem of clustering a set of points so as to minimize the maximum intercluster distance is studied. An O(kn) approximation algorithm, where n is the number of points and k is the number of clusters, that guarantees solutions with an objective function value within two times the optimal solution value is presented. This approximation algorithm succeeds as long as the set of points satisfies the triangular inequality. We also show that our approximation algorithm is best possible, with respect to the approximation bound, if {PZ} {NP}.},
	pages = {293--306},
	journaltitle = {Theoretical Computer Science},
	shortjournal = {Theoretical Computer Science},
	author = {Gonzalez, Teofilo F.},
	urldate = {2020-10-10},
	date = {1985},
	langid = {english},
	keywords = {viewed},
}

@incollection{battiti_new_2017,
	location = {Cham},
	title = {A New Local Search for the p-Center Problem Based on the Critical Vertex Concept},
	volume = {10556},
	isbn = {978-3-319-69403-0},
	url = {http://link.springer.com/10.1007/978-3-319-69404-7_6},
	abstract = {We propose a new smart local search for the p-center problem, based on the critical vertex concept, and embed it in a {GRASP} framework. Experimental results attest the robustness of the proposed search procedure and conﬁrm that for benchmark instances it converges to optimal or near/optimal solutions faster than the best known state-of-the-art local search.},
	pages = {79--92},
	booktitle = {Learning and Intelligent Optimization},
	publisher = {Springer International Publishing},
	author = {Ferone, Daniele and Festa, Paola and Napoletano, Antonio and Resende, Mauricio G. C.},
	editor = {Battiti, Roberto and Kvasov, Dmitri E. and Sergeyev, Yaroslav D.},
	urldate = {2021-02-14},
	date = {2017},
	langid = {english},
	doi = {10.1007/978-3-319-69404-7_6},
	note = {Series Title: Lecture Notes in Computer Science},
	file = {Ferone et al. - 2017 - A New Local Search for the p-Center Problem Based .pdf:C\:\\Users\\timch\\Zotero\\storage\\DSP4UTUF\\Ferone et al. - 2017 - A New Local Search for the p-Center Problem Based .pdf:application/pdf},
}

@article{feo_greedy_1995,
	title = {Greedy Randomized Adaptive Search Procedures},
	volume = {6},
	issn = {1573-2916},
	url = {https://doi.org/10.1007/BF01096763},
	doi = {10.1007/BF01096763},
	abstract = {Today, a variety of heuristic approaches are available to the operations research practitioner. One methodology that has a strong intuitive appeal, a prominent empirical track record, and is trivial to efficiently implement on parallel processors is {GRASP} (Greedy Randomized Adaptive Search Procedures). {GRASP} is an iterative randomized sampling technique in which each iteration provides a solution to the problem at hand. The incumbent solution over all {GRASP} iterations is kept as the final result. There are two phases within each {GRASP} iteration: the first intelligently constructs an initial solution via an adaptive randomized greedy function; the second applies a local search procedure to the constructed solution in hope of finding an improvement. In this paper, we define the various components comprising a {GRASP} and demonstrate, step by step, how to develop such heuristics for combinatorial optimization problems. Intuitive justifications for the observed empirical behavior of the methodology are discussed. The paper concludes with a brief literature review of {GRASP} implementations and mentions two industrial applications.},
	pages = {109--133},
	number = {2},
	journaltitle = {Journal of Global Optimization},
	shortjournal = {J Glob Optim},
	author = {Feo, Thomas A. and Resende, Mauricio G. C.},
	urldate = {2021-03-03},
	date = {1995-03-01},
	langid = {english},
	file = {Submitted Version:C\:\\Users\\timch\\Zotero\\storage\\78HSJCLC\\Feo and Resende - 1995 - Greedy Randomized Adaptive Search Procedures.pdf:application/pdf},
}

@article{al_nuaimi_applications_2015,
	title = {Applications of big data to smart cities},
	volume = {6},
	issn = {1869-0238},
	url = {https://doi.org/10.1186/s13174-015-0041-5},
	doi = {10.1186/s13174-015-0041-5},
	abstract = {Many governments are considering adopting the smart city concept in their cities and implementing big data applications that support smart city components to reach the required level of sustainability and improve the living standards. Smart cities utilize multiple technologies to improve the performance of health, transportation, energy, education, and water services leading to higher levels of comfort of their citizens. This involves reducing costs and resource consumption in addition to more effectively and actively engaging with their citizens. One of the recent technologies that has a huge potential to enhance smart city services is big data analytics. As digitization has become an integral part of everyday life, data collection has resulted in the accumulation of huge amounts of data that can be used in various beneficial application domains. Effective analysis and utilization of big data is a key factor for success in many business and service domains, including the smart city domain. This paper reviews the applications of big data to support smart cities. It discusses and compares different definitions of the smart city and big data and explores the opportunities, challenges and benefits of incorporating big data applications for smart cities. In addition it attempts to identify the requirements that support the implementation of big data applications for smart city services. The review reveals that several opportunities are available for utilizing big data in smart cities; however, there are still many issues and challenges to be addressed to achieve better utilization of this technology.},
	pages = {25},
	number = {1},
	journaltitle = {Journal of Internet Services and Applications},
	shortjournal = {Journal of Internet Services and Applications},
	author = {Al Nuaimi, Eiman and Al Neyadi, Hind and Mohamed, Nader and Al-Jaroodi, Jameela},
	urldate = {2021-03-06},
	date = {2015-12-01},
	keywords = {Application of big data, Application of smart city, Big data, Smart city},
	file = {Full Text PDF:C\:\\Users\\timch\\Zotero\\storage\\TVKSYTNM\\Al Nuaimi et al. - 2015 - Applications of big data to smart cities.pdf:application/pdf;Snapshot:C\:\\Users\\timch\\Zotero\\storage\\MX8DHVK2\\s13174-015-0041-5.html:text/html},
}

@article{hochbaum_best_1985,
	title = {A Best Possible Heuristic for the k-Center Problem},
	volume = {10},
	doi = {10.1287/moor.10.2.180},
	abstract = {In this paper we present a 2-approximation algorithm for the k-center problem with triangle inequality. This result is “best possible” since for any δ {\textless} 2 the existence of δ-approximation algorithm would imply that P = {NP}. It should be noted that no δ-approximation algorithm, for any constant δ, has been reported to date. Linear programming duality theory provides interesting insight to the problem and enables us to derive, in O{\textbar}E{\textbar} log {\textbar}E{\textbar} time, a solution with value no more than twice the k-center optimal value.

A by-product of the analysis is an O{\textbar}E{\textbar} algorithm that identifies a dominating set in G2, the square of a graph G, the size of which is no larger than the size of the minimum dominating set in the graph G. The key combinatorial object used is called a strong stable set, and we prove the {NP}-completeness of the corresponding decision problem.},
	pages = {180--184},
	journaltitle = {Mathematics of Operations Research - {MOR}},
	shortjournal = {Mathematics of Operations Research - {MOR}},
	author = {Hochbaum, Dorit and Shmoys, David},
	date = {1985-05-01},
	file = {Full Text PDF:C\:\\Users\\timch\\Zotero\\storage\\YPSKIS5G\\Hochbaum and Shmoys - 1985 - A Best Possible Heuristic for the k-Center Problem.pdf:application/pdf},
}

@article{mladenovic_solving_2003,
	title = {Solving the p-Center problem with Tabu Search and Variable Neighborhood Search},
	volume = {42},
	issn = {1097-0037},
	url = {http://onlinelibrary.wiley.com/doi/abs/10.1002/net.10081},
	doi = {10.1002/net.10081},
	abstract = {The p-Center problem consists of locating p facilities and assigning clients to them in order to minimize the maximum distance between a client and the facility to which he or she is allocated. In this paper, we present a basic Variable Neighborhood Search and two Tabu Search heuristics for the p-Center problem without the triangle inequality. Both proposed methods use the 1-interchange (or vertex substitution) neighborhood structure. We show how this neighborhood can be used even more efficiently than for solving the p-Median problem. Multistart 1-interchange, Variable Neighborhood Search, Tabu Search, and a few early heuristics are compared on small- and large-scale test problems from the literature. © 2003 Wiley Periodicals, Inc.},
	pages = {48--64},
	number = {1},
	journaltitle = {Networks},
	author = {Mladenović, Nenad and Labbé, Martine and Hansen, Pierre},
	urldate = {2020-10-23},
	date = {2003},
	langid = {english},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/net.10081},
	keywords = {unread, heuristics, location, variable neighborhood search, p-center, tabu search},
	file = {Full Text PDF:C\:\\Users\\timch\\Zotero\\storage\\GF3PYQF5\\Mladenović et al. - 2003 - Solving the p-Center problem with Tabu Search and .pdf:application/pdf;Snapshot:C\:\\Users\\timch\\Zotero\\storage\\VMSKL823\\net.html:text/html},
}

@article{hakimi_optimum_1965,
	title = {Optimum Distribution of Switching Centers in a Communication Network and Some Related Graph Theoretic Problems},
	volume = {13},
	issn = {0030-364X},
	url = {https://www.jstor.org/stable/167810},
	abstract = {The concept of a median in a weighted graph is generalized to a multimedian. Then, it is shown that the optimum distribution of p switching centers in a communication network is at a p-median of the corresponding weighted graph. The following related problem in highway networks is also considered: What is a minimum number of policemen that can be distributed in a highway network so that no one is farther away from a policeman than a given distance d? This problem is attacked by generating all vertex-coverings (externally stable sets) of a graph by means of a Boolean function defined over the vertices of a graph. Then this idea is extended to Boolean functions that generate all matchings, all factors, and all possible subgraphs of G with given degrees.},
	pages = {462--475},
	number = {3},
	journaltitle = {Operations Research},
	author = {Hakimi, S. L.},
	urldate = {2021-03-07},
	date = {1965},
	note = {Publisher: {INFORMS}},
	file = {JSTOR Full Text PDF:C\:\\Users\\timch\\Zotero\\storage\\YGIIXGE3\\Hakimi - 1965 - Optimum Distribution of Switching Centers in a Com.pdf:application/pdf},
}

@article{mladenovic_variable_1997,
	title = {Variable neighborhood search},
	volume = {24},
	issn = {0305-0548},
	url = {https://www.sciencedirect.com/science/article/pii/S0305054897000312},
	doi = {10.1016/S0305-0548(97)00031-2},
	abstract = {Systematic change of neighborhood within a local search algorithm yields a simple and effective metaheuristic for combinatorial optimization. We present a basic scheme for this purpose which can be implemented easily using any local search algorithm as a subroutine. Its effectiveness is illustrated by improvements in the {GENIUS} algorithm for the traveling salesman problem [1], without and with backhauls [2].},
	pages = {1097--1100},
	number = {11},
	journaltitle = {Computers \& Operations Research},
	shortjournal = {Computers \& Operations Research},
	author = {Mladenović, N. and Hansen, P.},
	urldate = {2021-03-14},
	date = {1997-11-01},
	langid = {english},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\timch\\Zotero\\storage\\RH8SRK9X\\Mladenović and Hansen - 1997 - Variable neighborhood search.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\timch\\Zotero\\storage\\T6MX2L44\\S0305054897000312.html:text/html},
}

@article{beasley_note_1985,
	title = {A note on solving large p-median problems},
	volume = {21},
	issn = {0377-2217},
	url = {https://www.sciencedirect.com/science/article/pii/0377221785900402},
	doi = {10.1016/0377-2217(85)90040-2},
	abstract = {In a previous paper we presented a tree search algorithm for the p-median problem, the problem of locating p facilities (medians) on a network, which was based upon La grangean relaxation and subgradient optimisation. That algorithm solved (optimally) problems with an arbitrary number of medians and having up to 200 vertices. In this note we show that it is possible to enhance that algorithm to solve (optimally) problems having up to 900 vertices using the Cray-1S computer.},
	pages = {270--273},
	number = {2},
	journaltitle = {European Journal of Operational Research},
	shortjournal = {European Journal of Operational Research},
	author = {Beasley, J. E.},
	urldate = {2021-03-16},
	date = {1985-08-01},
	langid = {english},
	keywords = {integer programming, Location, networks},
	file = {ScienceDirect Snapshot:C\:\\Users\\timch\\Zotero\\storage\\E6V97YJD\\0377221785900402.html:text/html},
}

@article{schwartz_efficient_2010,
	title = {An Efficient Implementation of the Robust k-Center Clustering Problem},
	abstract = {The standard k-center clustering problem is very sensitive to outliers. Charikar et al. proposed an alternative algorithm to cluster p points out of n total, thereby avoiding the distortion caused by outliers. The algorithm has an approximation bound of three times the true solution, but is very slow if implemented naively. We propose a modified implementation of the algorithm that runs significantly faster than the standard version. It does this while keeping the memory bound within the same asymptotic bound as that of the naive implementation. We show that, as the size of the problem increases, our algorithm maintains a relatively low running time, while the standard implementation time increases in proportion to it.},
	author = {Schwartz, Rachel},
	date = {2010-06-19},
}

@article{jia_fair_2020,
	title = {Fair Colorful k-Center Clustering},
	volume = {12125},
	url = {http://arxiv.org/abs/2007.04059},
	doi = {10.1007/978-3-030-45771-6_17},
	abstract = {An instance of colorful k-center consists of points in a metric space that are colored red or blue, along with an integer k and a coverage requirement for each color. The goal is to find the smallest radius {\textbackslash}r\{ho\} such that there exist balls of radius {\textbackslash}r\{ho\} around k of the points that meet the coverage requirements. The motivation behind this problem is twofold. First, from fairness considerations: each color/group should receive a similar service guarantee, and second, from the algorithmic challenges it poses: this problem combines the difficulties of clustering along with the subset-sum problem. In particular, we show that this combination results in strong integrality gap lower bounds for several natural linear programming relaxations. Our main result is an efficient approximation algorithm that overcomes these difficulties to achieve an approximation guarantee of 3, nearly matching the tight approximation guarantee of 2 for the classical k-center problem which this problem generalizes.},
	pages = {209--222},
	journaltitle = {{arXiv}:2007.04059 [cs]},
	author = {Jia, Xinrui and Sheth, Kshiteej and Svensson, Ola},
	urldate = {2020-10-10},
	date = {2020},
	eprinttype = {arxiv},
	eprint = {2007.04059},
	keywords = {viewed, Computer Science - Data Structures and Algorithms, F.2.2, high},
	file = {arXiv.org Snapshot:C\:\\Users\\timch\\Zotero\\storage\\ZAWX8GDJ\\2007.html:text/html;arXiv Fulltext PDF:C\:\\Users\\timch\\Zotero\\storage\\N4RMFICP\\Jia et al. - 2020 - Fair Colorful k-Center Clustering.pdf:application/pdf},
}

@incollection{kramer_genetic_2017,
	location = {Cham},
	title = {Genetic Algorithms},
	isbn = {978-3-319-52156-5},
	url = {https://doi.org/10.1007/978-3-319-52156-5_2},
	series = {Studies in Computational Intelligence},
	abstract = {Genetic Algorithms are heuristic search approaches that are applicable to a wide range of optimization problems. This flexibility makes them attractive for many optimization problems in practice. Evolution is the basis of Genetic Algorithms. The current variety and success of species is a good reason for believing in the power of evolution. Species are able to adapt to their environment. They have developed to complex structures that allow the survival in different kinds of environments. Mating and getting offspring to evolve belong to the main principles of the success of evolution. These are good reasons for adapting evolutionary principles to solving optimization problems.},
	pages = {11--19},
	booktitle = {Genetic Algorithm Essentials},
	publisher = {Springer International Publishing},
	author = {Kramer, Oliver},
	editor = {Kramer, Oliver},
	urldate = {2021-03-23},
	date = {2017},
	langid = {english},
	doi = {10.1007/978-3-319-52156-5_2},
	keywords = {Crossover Operator, Fitness Function, Genetic Algorithm, Mutation Operator, Solution Space},
}

@book{dawkins_selfish_1976,
	title = {The Selfish Gene},
	isbn = {978-0-19-286092-7},
	abstract = {Richard Dawkins' brilliant reformulation of the theory of natural selection has the rare distinction of having provoked as much excitement and interest outside the scientific community as within it. His theories have helped change the whole nature of the study of social biology, and have forced thousands of readers to rethink their beliefs about life. In his internationally bestselling, now classic volume, The Selfish Gene, Dawkins explains how the selfish gene can also be a subtle gene. The world of the selfish gene revolves around savage competition, ruthless exploitation, and deceit, and yet, Dawkins argues, acts of apparent altruism do exist in nature. Bees, for example, will commit suicide when they sting to protect the hive, and birds will risk their lives to warn the flock of an approaching hawk. This revised edition of Dawkins' fascinating book contains two new chapters. One, entitled "Nice Guys Finish First," demonstrates how cooperation can evolve even in a basically selfish world. The other new chapter, entitled "The Long Reach of the Gene," which reflects the arguments presented in Dawkins' The Extended Phenotype, clarifies the startling view that genes may reach outside the bodies in which they dwell and manipulate other individuals and even the world at large. Containing a wealth of remarkable new insights into the biological world, the second edition once again drives home the fact that truth is stranger than fiction.},
	pagetotal = {372},
	publisher = {Oxford University Press},
	author = {Dawkins, Richard},
	date = {1976},
	langid = {english},
	note = {Google-Books-{ID}: {WkHO}9HI7koEC},
	keywords = {Literary Criticism / American / African American},
}

@book{moscato_evolution_1989,
	title = {On Evolution, Search, Optimization, Genetic Algorithms and Martial Arts - Towards Memetic Algorithms},
	abstract = {Short abstract, isn't it?  P.A.C.S. numbers 05.20, 02.50, 87.10  1 Introduction  Large Numbers  "...the optimal tour displayed (see Figure 6) is the possible unique tour having one arc fixed from among 10  655  tours that are possible among 318 points and have one arc fixed. Assuming that one could possibly enumerate 10  9  tours per second on a computer it would thus take roughly 10  639  years of computing to establish the optimality of this tour by exhaustive enumeration."  This quote shows the real difficulty of a combinatorial optimization problem. The huge number of configurations is the primary difficulty when dealing with one of these problems. The quote belongs to M.W Padberg and M. Grotschel, Chap. 9., "Polyhedral computations", from the book The Traveling Salesman Problem: A Guided tour of Combinatorial Optimization [124].  It is interesting to compare the number of configurations of real-world problems in combinatorial optimization with those large numbers arising in Cosmol...},
	author = {Moscato, Pablo},
	date = {1989},
	file = {Citeseer - Full Text PDF:C\:\\Users\\timch\\Zotero\\storage\\WYLT63IH\\Moscato - 1989 - On Evolution, Search, Optimization, Genetic Algori.pdf:application/pdf;Citeseer - Snapshot:C\:\\Users\\timch\\Zotero\\storage\\AFTV3S32\\download.html:text/html},
}

@incollection{wilcoxon_individual_1992,
	location = {New York, {NY}},
	title = {Individual Comparisons by Ranking Methods},
	isbn = {978-1-4612-4380-9},
	url = {https://doi.org/10.1007/978-1-4612-4380-9_16},
	series = {Springer Series in Statistics},
	abstract = {The comparison of two treatments generally falls into one of the following two categories: (a) we may have a number of replications for each of the two treatments, which are unpaired, or (b) we may have a number of paired comparisons leading to a series of differences, some of which may be positive and some negative. The appropriate methods for testing the significance of the differences of the means in these two cases are described in most of the textbooks on statistical methods.},
	pages = {196--202},
	booktitle = {Breakthroughs in Statistics: Methodology and Distribution},
	publisher = {Springer},
	author = {Wilcoxon, Frank},
	editor = {Kotz, Samuel and Johnson, Norman L.},
	urldate = {2021-03-24},
	date = {1992},
	langid = {english},
	doi = {10.1007/978-1-4612-4380-9_16},
	keywords = {Individual Comparison, Negative Difference, Paired Comparison, Ranking Method, Serial Number},
}

@book{matousek_understanding_2007,
	title = {Understanding and Using Linear Programming},
	isbn = {978-3-540-30717-4},
	abstract = {This is an introductory textbook of linear programming, written mainly for students of computer science and mathematics. Our guiding phrase is, “what everytheoreticalcomputerscientistshouldknowaboutlinearprogramming.” The book is relatively concise, in order to allow the reader to focus on the basic ideas. For a number of topics commonly appearing in thicker books on the subject, we were seriously tempted to add them to the main text, but we decided to present them only very brie?y in a separate glossary. At the same time, we aim at covering the main results with complete proofs and in su?cient detail, in a way ready for presentation in class. One of the main focuses is applications of linear programming, both in practice and in theory. Linear programming has become an extremely ?- ible tool in theoretical computer science and in mathematics. While many of the ?nest modern applications are much too complicated to be included in an introductory text, we hope to communicate some of the ?avor (and excitement) of such applications on simpler examples.},
	pagetotal = {230},
	publisher = {Springer Science \& Business Media},
	author = {Matousek, Jiri and Gärtner, Bernd},
	date = {2007-07-04},
	langid = {english},
	note = {Google-Books-{ID}: 6MO\_RS4z0w8C},
	keywords = {Business \& Economics / Operations Research, Computers / Data Processing, Mathematics / Applied, Mathematics / Discrete Mathematics, Mathematics / General, Mathematics / Optimization},
}

@article{klee_simplex_1972,
author="Klee, Victor and Minty, George J.",
title="How good is the simplex algorithm?",
journal="Inequalities",
ISSN="",
publisher="Academic Press",
year="1972",
month="",
volume="III",
number="",
pages="159-175",
URL="https://ci.nii.ac.jp/naid/10020194052/en/",
DOI="",
}

@incollection{dantzig_origins_1990,
	location = {New York, {NY}, {USA}},
	title = {Origins of the simplex method},
	isbn = {978-0-201-50814-7},
	url = {https://doi.org/10.1145/87252.88081},
	pages = {141--151},
	booktitle = {A history of scientific computing},
	publisher = {Association for Computing Machinery},
	author = {Dantzig, George B.},
	urldate = {2021-03-29},
	date = {1990-06-01},
}

@inproceedings{spielman_smoothed_2001,
	location = {New York, {NY}, {USA}},
	title = {Smoothed analysis of algorithms: why the simplex algorithm usually takes polynomial time},
	isbn = {978-1-58113-349-3},
	url = {https://doi.org/10.1145/380752.380813},
	doi = {10.1145/380752.380813},
	series = {{STOC} '01},
	shorttitle = {Smoothed analysis of algorithms},
	abstract = {We introduce the smoothed analysis of algorithms, which is a hybrid of the worst-case and average-case analysis of algorithms. Essentially, we study the performance of algorithms under small random perturbations of their inputs. We show that the shadow-vertex simplex algorithm has polynomial smoothed complexity.},
	pages = {296--305},
	booktitle = {Proceedings of the thirty-third annual {ACM} symposium on Theory of computing},
	publisher = {Association for Computing Machinery},
	author = {Spielman, Daniel and Teng, Shang-Hua},
	urldate = {2021-03-29},
	date = {2001-07-06},
	file = {Full Text PDF:C\:\\Users\\timch\\Zotero\\storage\\XSNAYRFC\\Spielman and Teng - 2001 - Smoothed analysis of algorithms why the simplex a.pdf:application/pdf},
}

@article{kotzias_predicting_2019,
	title = {Predicting Consumption Patterns with Repeated and Novel Events},
	volume = {31},
	issn = {1558-2191},
	doi = {10.1109/TKDE.2018.2832132},
	abstract = {There are numerous contexts where individuals typically consume a few items from a large selection of possible items. Examples include purchasing products, listening to music, visiting locations in physical or virtual environments, and so on. There has been significant prior work in such contexts on developing predictive modeling techniques for recommending new items to individuals, often using techniques such as matrix factorization. There are many situations, however, where making predictions for both previously-consumed and new items for an individual is important, rather than just recommending new items. We investigate this problem and find that widely-used matrix factorization methods are limited in their ability to capture important details in historical behavior, resulting in relatively low predictive accuracy for these types of problems. As an alternative we propose an interpretable and scalable mixture model framework that balances individual preferences in terms of exploration and exploitation. We evaluate our model in terms of accuracy in user consumption predictions using several real-world datasets, including location data, social media data, and music listening data. Experimental results show that the mixture model approach is systematically more accurate and more efficient for these problems compared to a variety of state-of-the-art matrix factorization methods.},
	pages = {371--384},
	number = {2},
	journaltitle = {{IEEE} Transactions on Knowledge and Data Engineering},
	author = {Kotzias, D. and Lichman, M. and Smyth, P.},
	date = {2019-02},
	note = {Conference Name: {IEEE} Transactions on Knowledge and Data Engineering},
	keywords = {Data models, mixture models, Mixture models, Motion pictures, Music, Personalization, Predictive models, repeat consumption, Social network services, Training data, user modeling},
	file = {IEEE Xplore Full Text PDF:C\:\\Users\\timch\\Zotero\\storage\\MB5VQ485\\Kotzias et al. - 2019 - Predicting Consumption Patterns with Repeated and .pdf:application/pdf;IEEE Xplore Abstract Record:C\:\\Users\\timch\\Zotero\\storage\\WI2N2FHA\\8353141.html:text/html},
}

@article{cho_friendship_2011,
	title = {Friendship and mobility: user movement in location-based social networks.},
	doi = {10.1145/2020408.2020579},
	shorttitle = {Friendship and mobility},
	pages = {1082--1090},
	author = {Cho, Eunjoon},
	date = {2011},
	file = {dblp\: Friendship and mobility\: user movement in location-based social networks.:C\:\\Users\\timch\\Zotero\\storage\\TKP2WCHY\\ChoML11.html:text/html},
}

@article{hart_pyomo_2011,
title={Pyomo: modeling and solving mathematical programs in Python},
author={Hart, William E and Watson, Jean-Paul and Woodruff, David L},
journal={Mathematical Programming Computation},
volume={3},
number={3},
pages={219--260},
year={2011},
publisher={Springer}
}

@article{nmeth_scipy_2020,
  author  = {Virtanen, Pauli and Gommers, Ralf and Oliphant, Travis E. and
            Haberland, Matt and Reddy, Tyler and Cournapeau, David and
            Burovski, Evgeni and Peterson, Pearu and Weckesser, Warren and
            Bright, Jonathan and {van der Walt}, St{\'e}fan J. and
            Brett, Matthew and Wilson, Joshua and Millman, K. Jarrod and
            Mayorov, Nikolay and Nelson, Andrew R. J. and Jones, Eric and
            Kern, Robert and Larson, Eric and Carey, C J and
            Polat, {\.I}lhan and Feng, Yu and Moore, Eric W. and
            {VanderPlas}, Jake and Laxalde, Denis and Perktold, Josef and
            Cimrman, Robert and Henriksen, Ian and Quintero, E. A. and
            Harris, Charles R. and Archibald, Anne M. and
            Ribeiro, Ant{\^o}nio H. and Pedregosa, Fabian and
            {van Mulbregt}, Paul and {SciPy 1.0 Contributors}},
  title   = {{{SciPy} 1.0: Fundamental Algorithms for Scientific
            Computing in Python}},
  journal = {Nature Methods},
  year    = {2020},
  volume  = {17},
  pages   = {261--272},
  adsurl  = {https://rdcu.be/b08Wh},
  doi     = {10.1038/s41592-019-0686-2},
}

@article{wilcoxon_individual_1945,
	title = {Individual Comparisons by Ranking Methods},
	volume = {1},
	issn = {0099-4987},
	url = {https://www.jstor.org/stable/3001968},
	doi = {10.2307/3001968},
	pages = {80--83},
	number = {6},
	journaltitle = {Biometrics Bulletin},
	author = {Wilcoxon, Frank},
	urldate = {2021-04-28},
	date = {1945},
	note = {Publisher: [International Biometric Society, Wiley]},
}

@article{conover_analysis_1982,
	title = {Analysis of Covariance Using the Rank Transformation},
	volume = {38},
	issn = {0006-341X},
	url = {https://www.jstor.org/stable/2530051},
	doi = {10.2307/2530051},
	abstract = {The rank transformation refers to the replacement of data by their ranks, with a subsequent analysis using the usual normal theory procedure, but calculated on the ranks rather than on the data. Rank transformation procedures have previously been shown by the authors to have properties of robustness and power in both regression and analysis of variance. It seems natural to consider the use of the rank transformation in analysis of covariance, which is a combination of regression and analysis of variance. In this paper the rank transformation approach to analysis of covariance is presented and examined. Comparisons are made with the rank transformation procedure given by Quade (1967, Journal of the American Statistical Association 62, 1187-1200), and some 'standard' data sets are used to compare the results of these two procedures. A Monte Carlo simulation study examines the behavior of these methods under the null hypothesis and under alternative hypotheses, with both normal and nonnormal distributions. All results are compared with the usual analysis of covariance procedure on the basis of robustness and power.},
	pages = {715--724},
	number = {3},
	journaltitle = {Biometrics},
	author = {Conover, W. J. and Iman, Ronald L.},
	urldate = {2021-04-28},
	date = {1982},
	note = {Publisher: [Wiley, International Biometric Society]},
}


@article{khachiyan_1979,
  title = {A Polynomial Algorithm in Linear Programming},
  author = {Khachiyan, L. G.},
  year = {1979},
  volume = {244},
  pages = {1093--1096},
  journal = {Doklady Academii Nauk SSSR}
}

@inproceedings{hagberg_exploring_2008,
	location = {Pasadena, {CA} {USA}},
	title = {Exploring Network Structure, Dynamics, and Function using {NetworkX}},
	pages = {11 -- 15},
	booktitle = {Proceedings of the 7th Python in Science Conference},
	author = {Hagberg, Aric A. and Schult, Daniel A. and Swart, Pieter J.},
	editor = {Varoquaux, Gaël and Vaught, Travis and Millman, Jarrod},
	date = {2008},
}

@article{reineltTSPLIBTravelingSalesman1991a,
  title = {{{TSPLIB}}\textemdash{{A Traveling Salesman Problem Library}}},
  author = {Reinelt, Gerhard},
  year = {1991},
  volume = {3},
  pages = {376--384},
  publisher = {{INFORMS}},
  issn = {1091-9856},
  abstract = {This paper contains the description of a traveling salesman problem library (TSPLIB) which is meant to provide researchers with a broad set of test problems from various sources and with various properties. For every problem a short description is given along with known lower and upper bounds. Several references to computational tests on some of the problems are given. INFORMS Journal on Computing , ISSN 1091-9856, was published as ORSA Journal on Computing from 1989 to 1995 under ISSN 0899-1499.},
  file = {C\:\\Users\\timch\\Zotero\\storage\\QEDQL7TE\\v_3a3_3ay_3a1991_3ai_3a4_3ap_3a376-384.html},
  journal = {INFORMS Journal on Computing},
  keywords = {a data base of test problem instances,a data base of test problems instances,networks/graphs: traveling salesman,traveling salesman problem},
  number = {4}
}

@software{jsLPSolver,
  author = {Wolcott, Justin W.},
  title = {jsLPSolver},
  url = {https://www.npmjs.com/package/javascript-lp-solver},
  version = {0.4.24},
  date = {2019-10-11},
}

@software{springboot,
  author = {Pivotal Software},
  title = {Spring Boot},
  url = {https://spring.io/projects/spring-boot},
  version = {2.4.4},
  date = {2021-03-18},
}

@software{typehints,
  author = {van Rossum, Guido and Lehtosalo, Jukka and Langa, Łukasz },
  title = {Python PEP 484: type hints},
  url = {https://www.python.org/dev/peps/pep-0484/},
  version = {3.5},
  date = {2015-09-13},
}

