
@article{bandyapadhyay_constant_2019,
	title = {A Constant Approximation for Colorful k-Center},
	url = {http://arxiv.org/abs/1907.08906},
	abstract = {In this paper, we consider the colorful \$k\$-center problem, which is a generalization of the well-known \$k\$-center problem. Here, we are given red and blue points in a metric space, and a coverage requirement for each color. The goal is to find the smallest radius \${\textbackslash}rho\$, such that with \$k\$ balls of radius \${\textbackslash}rho\$, the desired number of points of each color can be covered. We obtain a constant approximation for this problem in the Euclidean plane. We obtain this result by combining a "pseudo-approximation" algorithm that works in any metric space, and an approximation algorithm that works for a special class of instances in the plane. The latter algorithm uses a novel connection to a certain matching problem in graphs.},
	journaltitle = {{arXiv}:1907.08906 [cs]},
	author = {Bandyapadhyay, Sayan and Inamdar, Tanmay and Pai, Shreyas and Varadarajan, Kasturi},
	urldate = {2020-10-12},
	date = {2019-07-20},
	eprinttype = {arxiv},
	eprint = {1907.08906},
	keywords = {Computer Science - Computational Geometry, Computer Science - Data Structures and Algorithms, high, viewed},
	file = {arXiv.org Snapshot:C\:\\Users\\timch\\Zotero\\storage\\QTMXZB9V\\1907.html:text/html;arXiv Fulltext PDF:C\:\\Users\\timch\\Zotero\\storage\\6LSAQ2GN\\Bandyapadhyay et al. - 2019 - A Constant Approximation for Colorful k-Center.pdf:application/pdf},
}

@article{hakimi_optimum_1964,
	title = {Optimum Locations of Switching Centers and the Absolute Centers and Medians of a Graph},
	volume = {12},
	issn = {0030-364X},
	url = {https://doi.org/10.1287/opre.12.3.450},
	doi = {10.1287/opre.12.3.450},
	abstract = {The concepts of the "center" and the "median vertex" of a graph are generalized to the "absolute center" and the "absolute median" of a weighted graph a graph with weights attached to its vertices as well as to its branches. These results are used to find the optimum location of a "switching center" in a communication network and to locate the best place to build a "police station" in a highway system. It is shown that the optimum location of a switching center is always at a vertex of the communication network while the best location for the police station is not necessarily at an intersection. Procedures for finding these locations are given.},
	pages = {450--459},
	number = {3},
	journaltitle = {Operations Research},
	shortjournal = {Oper. Res.},
	author = {Hakimi, S. L.},
	urldate = {2021-02-21},
	date = {1964-06-01},
}

@article{kariv_algorithmic_1979,
	title = {An Algorithmic Approach to Network Location Problems. I: The p-Centers},
	volume = {37},
	issn = {0036-1399},
	url = {https://www.jstor.org/stable/2100910},
	shorttitle = {An Algorithmic Approach to Network Location Problems. I},
	abstract = {Problems of finding p-centers and dominating sets of radius r in networks are discussed in this paper. Let n be the number of vertices and {\textbar}E{\textbar} be the number of edges of a network. With the assumption that the distance-matrix of the network is available, we design an \$O({\textbar}E{\textbar} {\textbackslash}cdot n {\textbackslash}cdot {\textbackslash}lg n)\$ algorithm for finding an absolute 1-center of a vertex-weighted network and an \$O({\textbar}E{\textbar} {\textbackslash}cdot n + n{\textasciicircum}2 {\textbackslash}cdot {\textbackslash}lg n)\$ algorithm for finding an absolute 1-center of a vertex-unweighted network (the problem of finding a vertex 1-center of a network is trivial). We show that the problem of finding a (vertex or absolute) p-center (for \$1 {\textless} p {\textless} n)\$ of a (vertex-weighted or vertex-unweighted) network, and the problem of finding a dominating set of radius r are {NP}-hard even in the case where the network has a simple structure (e.g., a planar graph of maximum vertex degree 3). However, we describe an algorithm of complexity \$O {\textbackslash}lbrack ({\textbar}E{\textbar}{\textasciicircum}p {\textbackslash}cdot n{\textasciicircum}\{2p - 1\}/(p - 1)!) {\textbackslash}lg n {\textbackslash}rbrack\$ (respectively, O [ {\textbar}E{\textbar}p · n2p - 1/(p - 1)! ]) for finding an absolute p-center in a vertex-weighted (respectively, vertex-unweighted) network. We proceed by discussing the problems of finding p-centers and dominating sets of networks whose underlying graphs are trees. When the network is a vertex-weighted tree, we obtain the following algorithms: An \$O(n {\textbackslash}cdot {\textbackslash}lg n)\$ algorithm for finding the (vertex or absolute) 1-center; an O(n) algorithm for finding a (vertex or absolute) dominating set of radius r; an \$O(n{\textasciicircum}2 {\textbackslash}cdot {\textbackslash}lg n)\$ algorithm for finding a (vertex or absolute) p-center for any \$1 {\textless} p {\textless} n\$. Some generalizations of these problems are discussed. When the network is a vertex-unweighted tree, O(n) algorithms for finding the (vertex or absolute) 1-center and an absolute 2-center are already known; we extend these results by giving an \$O(n {\textbackslash}cdot {\textbackslash}lg{\textasciicircum}\{p - 2\} n)\$ algorithm for finding an absolute p-center (where \$3 {\textbackslash}leqq p {\textless} n)\$ and an \$O(n {\textbackslash}cdot {\textbackslash}lg{\textasciicircum}\{p - 1\} n)\$ algorithm for finding a vertex p-center (where \$2 {\textbackslash}leqq p {\textless} n)\$. In part {II} we treat the p-median problem.},
	pages = {513--538},
	number = {3},
	journaltitle = {{SIAM} Journal on Applied Mathematics},
	author = {Kariv, O. and Hakimi, S. L.},
	urldate = {2021-02-21},
	date = {1979},
	note = {Publisher: Society for Industrial and Applied Mathematics},
}

@inproceedings{charikar_algorithms_2001,
	title = {Algorithms for facility location problems with outliers},
	doi = {10.1145/365411.365555},
	abstract = {Facility location problems are traditionally investigated with the assumption that all the clients are to be provided service. A significant shortcoming of this formulation is that a few very distant clients, called outliers, can exert a disproportionately strong influence over the final solution. In this paper we explore a generalization of various facility location problems (K-center, K-median, uncapacitated facility location etc) to the case when only a specified fraction of the customers are to be served. What makes the problems harder is that we have to also select the subset that should get service. We provide generalizations of various approximation algorithms to deal with this added constraint.},
	eventtitle = {Proceedings of {SODA}},
	pages = {642--651},
	author = {Charikar, Moses and Khuller, Samir and Mount, David and Narasimhan, Giri},
	date = {2001-01-01},
	file = {Full Text PDF:C\:\\Users\\timch\\Zotero\\storage\\92TTFV9F\\Charikar et al. - 2001 - Algorithms for facility location problems with out.pdf:application/pdf},
}

@article{obermeyer_predicting_2016,
	title = {Predicting the Future — Big Data, Machine Learning, and Clinical Medicine},
	volume = {375},
	issn = {0028-4793},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5070532/},
	doi = {10.1056/NEJMp1606181},
	pages = {1216--1219},
	number = {13},
	journaltitle = {The New England journal of medicine},
	shortjournal = {N Engl J Med},
	author = {Obermeyer, Ziad and Emanuel, Ezekiel J.},
	urldate = {2021-02-28},
	date = {2016-09-29},
	pmid = {27682033},
	pmcid = {PMC5070532},
	file = {PubMed Central Full Text PDF:C\:\\Users\\timch\\Zotero\\storage\\I3T24SX4\\Obermeyer and Emanuel - 2016 - Predicting the Future — Big Data, Machine Learning.pdf:application/pdf},
}

@book{zhao_parallel_1970,
	title = {Parallel K-Means Clustering Based on {MapReduce}},
	volume = {5931},
	isbn = {978-3-642-10664-4},
	abstract = {Data clustering has been received considerable attention in many applications, such as data mining, document retrieval, image
segmentation and pattern classification. The enlarging volumes of information emerging by the progress of technology, makes
clustering of very large scale of data a challenging task. In order to deal with the problem, many researchers try to design
efficient parallel clustering algorithms. In this paper, we propose a parallel k-means clustering algorithm based on {MapReduce}, which is a simple yet powerful parallel programming technique. The experimental
results demonstrate that the proposed algorithm can scale well and efficiently process large datasets on commodity hardware.},
	pagetotal = {674},
	author = {Zhao, Weizhong and Ma, Huifang and He, Qing},
	date = {1970-01-01},
	doi = {10.1007/978-3-642-10665-1_71},
	note = {Journal Abbreviation: Cloud computing
Pages: 679
Publication Title: Cloud computing},
}

@article{dean_mapreduce_2008,
	title = {{MapReduce}: simplified data processing on large clusters},
	volume = {51},
	issn = {0001-0782},
	url = {https://doi.org/10.1145/1327452.1327492},
	doi = {10.1145/1327452.1327492},
	shorttitle = {{MapReduce}},
	abstract = {{MapReduce} is a programming model and an associated implementation for processing and generating large datasets that is amenable to a broad variety of real-world tasks. Users specify the computation in terms of a map and a reduce function, and the underlying runtime system automatically parallelizes the computation across large-scale clusters of machines, handles machine failures, and schedules inter-machine communication to make efficient use of the network and disks. Programmers find the system easy to use: more than ten thousand distinct {MapReduce} programs have been implemented internally at Google over the past four years, and an average of one hundred thousand {MapReduce} jobs are executed on Google's clusters every day, processing a total of more than twenty petabytes of data per day.},
	pages = {107--113},
	number = {1},
	journaltitle = {Communications of the {ACM}},
	shortjournal = {Commun. {ACM}},
	author = {Dean, Jeffrey and Ghemawat, Sanjay},
	urldate = {2021-02-28},
	date = {2008-01-01},
}

@article{pullan_memetic_2008,
	title = {A Memetic Genetic Algorithm for the Vertex \textit{p} -center Problem},
	volume = {16},
	issn = {1063-6560, 1530-9304},
	url = {https://www.mitpressjournals.org/doi/abs/10.1162/evco.2008.16.3.417},
	doi = {10.1162/evco.2008.16.3.417},
	abstract = {The p-center problem is one of choosing p facilities from a set of candidates to satisfy the demands of n clients in order to minimize the maximum cost between a client and the facility to which it is assigned. In this article, {PBS}, a population based meta-heuristic for the p-center problem, is described. {PBS} is a genetic algorithm based meta-heuristic that uses phenotype crossover and directed mutation operators to generate new starting points for a local search. For larger p-center instances, {PBS} is able to effectively utilize a number of computer processors. It is shown empirically that {PBS} has comparable performance to state-of-the-art exact and approximate algorithms for a range of pcenter benchmark instances.},
	pages = {417--436},
	number = {3},
	journaltitle = {Evolutionary Computation},
	shortjournal = {Evolutionary Computation},
	author = {Pullan, Wayne},
	urldate = {2020-10-12},
	date = {2008-09},
	langid = {english},
	keywords = {viewed, high},
	file = {Pullan - 2008 - A Memetic Genetic Algorithm for the Vertex pi.pdf:C\:\\Users\\timch\\Zotero\\storage\\W2Z8564J\\Pullan - 2008 - A Memetic Genetic Algorithm for the Vertex pi.pdf:application/pdf},
}

@inproceedings{agarwal_structured_2003,
	location = {New York, {NY}, {USA}},
	title = {Structured importance sampling of environment maps},
	isbn = {978-1-58113-709-5},
	url = {https://doi.org/10.1145/1201775.882314},
	doi = {10.1145/1201775.882314},
	series = {{SIGGRAPH} '03},
	abstract = {We introduce structured importance sampling, a new technique for efficiently rendering scenes illuminated by distant natural illumination given in an environment map. Our method handles occlusion, high-frequency lighting, and is significantly faster than alternative methods based on Monte Carlo sampling. We achieve this speedup as a result of several ideas. First, we present a new metric for stratifying and sampling an environment map taking into account both the illumination intensity as well as the expected variance due to occlusion within the scene. We then present a novel hierarchical stratification algorithm that uses our metric to automatically stratify the environment map into regular strata. This approach enables a number of rendering optimizations, such as pre-integrating the illumination within each stratum to eliminate noise at the cost of adding bias, and sorting the strata to reduce the number of sample rays. We have rendered several scenes illuminated by natural lighting, and our results indicate that structured importance sampling is better than the best previous Monte Carlo techniques, requiring one to two orders of magnitude fewer samples for the same image quality.},
	pages = {605--612},
	booktitle = {{ACM} {SIGGRAPH} 2003 Papers},
	publisher = {Association for Computing Machinery},
	author = {Agarwal, Sameer and Ramamoorthi, Ravi and Belongie, Serge and Jensen, Henrik Wann},
	urldate = {2021-03-01},
	date = {2003-07-01},
	keywords = {environment mapping, global illumination, illumination, image synthesis, Monte Carlo techniques, ray tracing, rendering, shadow algorithms},
	file = {Full Text PDF:C\:\\Users\\timch\\Zotero\\storage\\C3MZIM6Q\\Agarwal et al. - 2003 - Structured importance sampling of environment maps.pdf:application/pdf},
}

@article{kleindessner_fair_2019,
	title = {Fair k-Center Clustering for Data Summarization},
	url = {http://arxiv.org/abs/1901.08628},
	abstract = {In data summarization we want to choose \$k\$ prototypes in order to summarize a data set. We study a setting where the data set comprises several demographic groups and we are restricted to choose \$k\_i\$ prototypes belonging to group \$i\$. A common approach to the problem without the fairness constraint is to optimize a centroid-based clustering objective such as \$k\$-center. A natural extension then is to incorporate the fairness constraint into the clustering problem. Existing algorithms for doing so run in time super-quadratic in the size of the data set, which is in contrast to the standard \$k\$-center problem being approximable in linear time. In this paper, we resolve this gap by providing a simple approximation algorithm for the \$k\$-center problem under the fairness constraint with running time linear in the size of the data set and \$k\$. If the number of demographic groups is small, the approximation guarantee of our algorithm only incurs a constant-factor overhead.},
	journaltitle = {{arXiv}:1901.08628 [cs, stat]},
	author = {Kleindessner, Matthäus and Awasthi, Pranjal and Morgenstern, Jamie},
	urldate = {2020-10-10},
	date = {2019-05-10},
	eprinttype = {arxiv},
	eprint = {1901.08628},
	keywords = {low, viewed, Computer Science - Data Structures and Algorithms, Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {arXiv.org Snapshot:C\:\\Users\\timch\\Zotero\\storage\\MB8ESKBZ\\1901.html:text/html;arXiv Fulltext PDF:C\:\\Users\\timch\\Zotero\\storage\\HDYASUVT\\Kleindessner et al. - 2019 - Fair k-Center Clustering for Data Summarization.pdf:application/pdf},
}

@article{do_sphetcher_2020,
	title = {Sphetcher: Spherical Thresholding Improves Sketching of Single-Cell Transcriptomic Heterogeneity},
	volume = {23},
	issn = {2589-0042},
	url = {https://www.sciencedirect.com/science/article/pii/S2589004220303114},
	doi = {10.1016/j.isci.2020.101126},
	shorttitle = {Sphetcher},
	abstract = {The massive size of single-cell {RNA} sequencing datasets often exceeds the capability of current computational analysis methods to solve routine tasks such as detection of cell types. Recently, geometric sketching was introduced as an alternative to uniform subsampling. It selects a subset of cells (the sketch) that evenly cover the transcriptomic space occupied by the original dataset, to accelerate downstream analyses and highlight rare cell types. Here, we propose algorithm Sphetcher that makes use of the thresholding technique to efficiently pick representative cells within spheres (as opposed to the typically used equal-sized boxes) that cover the entire transcriptomic space. We show that the spherical sketch computed by Sphetcher constitutes a more accurate representation of the original transcriptomic landscape. Our optimization scheme allows to include fairness aspects that can encode prior biological or experimental knowledge. We show how a fair sampling can inform the inference of the trajectory of human skeletal muscle myoblast differentiation.},
	pages = {101126},
	number = {6},
	journaltitle = {{iScience}},
	shortjournal = {{iScience}},
	author = {Do, Van Hoan and Elbassioni, Khaled and Canzar, Stefan},
	urldate = {2021-03-01},
	date = {2020-06-26},
	langid = {english},
	keywords = {Bioinformatics, Data Analysis, Transcriptomics},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\timch\\Zotero\\storage\\WP99ZVAG\\Do et al. - 2020 - Sphetcher Spherical Thresholding Improves Sketchi.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\timch\\Zotero\\storage\\YWEGD892\\S2589004220303114.html:text/html},
}

@article{anegg_technique_2020,
	title = {A Technique for Obtaining True Approximations for \$k\$-Center with Covering Constraints},
	url = {http://arxiv.org/abs/2007.03946},
	abstract = {There has been a recent surge of interest in incorporating fairness aspects into classical clustering problems. Two recently introduced variants of the \$k\$-Center problem in this spirit are Colorful \$k\$-Center, introduced by Bandyapadhyay, Inamdar, Pai, and Varadarajan, and lottery models, such as the Fair Robust \$k\$-Center problem introduced by Harris, Pensyl, Srinivasan, and Trinh. To address fairness aspects, these models, compared to traditional \$k\$-Center, include additional covering constraints. Prior approximation results for these models require to relax some of the normally hard constraints, like the number of centers to be opened or the involved covering constraints, and therefore, only obtain constant-factor pseudo-approximations. In this paper, we introduce a new approach to deal with such covering constraints that leads to (true) approximations, including a \$4\$-approximation for Colorful \$k\$-Center with constantly many colors---settling an open question raised by Bandyapadhyay, Inamdar, Pai, and Varadarajan---and a \$4\$-approximation for Fair Robust \$k\$-Center, for which the existence of a (true) constant-factor approximation was also open. We complement our results by showing that if one allows an unbounded number of colors, then Colorful \$k\$-Center admits no approximation algorithm with finite approximation guarantee, assuming that \${\textbackslash}mathrm\{P\} {\textbackslash}neq {\textbackslash}mathrm\{{NP}\}\$. Moreover, under the Exponential Time Hypothesis, the problem is inapproximable if the number of colors grows faster than logarithmic in the size of the ground set.},
	journaltitle = {{arXiv}:2007.03946 [cs, math]},
	author = {Anegg, Georg and Angelidakis, Haris and Kurpisz, Adam and Zenklusen, Rico},
	urldate = {2020-10-12},
	date = {2020-07-08},
	eprinttype = {arxiv},
	eprint = {2007.03946},
	keywords = {unread, Computer Science - Data Structures and Algorithms, 90C27, 68W40, 68Q25, 90C05, Mathematics - Optimization and Control},
	file = {arXiv.org Snapshot:C\:\\Users\\timch\\Zotero\\storage\\6GJ55JPL\\2007.html:text/html;arXiv Fulltext PDF:C\:\\Users\\timch\\Zotero\\storage\\9MQM3WPG\\Anegg et al. - 2020 - A Technique for Obtaining True Approximations for .pdf:application/pdf},
}

@article{harris_lottery_2017,
	title = {A Lottery Model for Center-type Problems With Outliers},
	url = {http://arxiv.org/abs/1710.00287},
	abstract = {In this paper, we give tight approximation algorithms for the \$k\$-center and matroid center problems with outliers. Unfairness arises naturally in this setting: certain clients could always be considered as outliers. To address this issue, we introduce a lottery model in which each client \$j\$ is allowed to submit a parameter \$p\_j {\textbackslash}in [0,1]\$ and we look for a random solution that covers every client \$j\$ with probability at least \$p\_j\$. Our techniques include a randomized rounding procedure to round a point inside a matroid intersection polytope to a basis plus at most one extra item such that all marginal probabilities are preserved and such that a certain linear function of the variables does not decrease in the process with probability one.},
	journaltitle = {{arXiv}:1710.00287 [cs]},
	author = {Harris, David G. and Pensyl, Thomas and Srinivasan, Aravind and Trinh, Khoa},
	urldate = {2021-03-01},
	date = {2017-09-30},
	eprinttype = {arxiv},
	eprint = {1710.00287},
	keywords = {Computer Science - Data Structures and Algorithms},
	file = {arXiv Fulltext PDF:C\:\\Users\\timch\\Zotero\\storage\\BSANCYZ9\\Harris et al. - 2017 - A Lottery Model for Center-type Problems With Outl.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\timch\\Zotero\\storage\\4NIHIJRR\\1710.html:text/html},
}

@article{mehrabi_survey_2019,
	title = {A Survey on Bias and Fairness in Machine Learning},
	url = {http://arxiv.org/abs/1908.09635},
	abstract = {With the widespread use of {AI} systems and applications in our everyday lives, it is important to take fairness issues into consideration while designing and engineering these types of systems. Such systems can be used in many sensitive environments to make important and life-changing decisions; thus, it is crucial to ensure that the decisions do not reflect discriminatory behavior toward certain groups or populations. We have recently seen work in machine learning, natural language processing, and deep learning that addresses such challenges in different subdomains. With the commercialization of these systems, researchers are becoming aware of the biases that these applications can contain and have attempted to address them. In this survey we investigated different real-world applications that have shown biases in various ways, and we listed different sources of biases that can affect {AI} applications. We then created a taxonomy for fairness definitions that machine learning researchers have defined in order to avoid the existing bias in {AI} systems. In addition to that, we examined different domains and subdomains in {AI} showing what researchers have observed with regard to unfair outcomes in the state-of-the-art methods and how they have tried to address them. There are still many future directions and solutions that can be taken to mitigate the problem of bias in {AI} systems. We are hoping that this survey will motivate researchers to tackle these issues in the near future by observing existing work in their respective fields.},
	journaltitle = {{arXiv}:1908.09635 [cs]},
	author = {Mehrabi, Ninareh and Morstatter, Fred and Saxena, Nripsuta and Lerman, Kristina and Galstyan, Aram},
	urldate = {2021-03-02},
	date = {2019-09-17},
	eprinttype = {arxiv},
	eprint = {1908.09635},
	keywords = {Computer Science - Machine Learning},
	file = {arXiv Fulltext PDF:C\:\\Users\\timch\\Zotero\\storage\\9J86WV33\\Mehrabi et al. - 2019 - A Survey on Bias and Fairness in Machine Learning.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\timch\\Zotero\\storage\\KIAHBP7Z\\1908.html:text/html},
}

@article{gonzalez_clustering_1985,
	title = {Clustering to minimize the maximum intercluster distance},
	volume = {38},
	issn = {03043975},
	url = {https://linkinghub.elsevier.com/retrieve/pii/0304397585902245},
	doi = {10.1016/0304-3975(85)90224-5},
	abstract = {The problem of clustering a set of points so as to minimize the maximum intercluster distance is studied. An O(kn) approximation algorithm, where n is the number of points and k is the number of clusters, that guarantees solutions with an objective function value within two times the optimal solution value is presented. This approximation algorithm succeeds as long as the set of points satisfies the triangular inequality. We also show that our approximation algorithm is best possible, with respect to the approximation bound, if {PZ} {NP}.},
	pages = {293--306},
	journaltitle = {Theoretical Computer Science},
	shortjournal = {Theoretical Computer Science},
	author = {Gonzalez, Teofilo F.},
	urldate = {2020-10-10},
	date = {1985},
	langid = {english},
	keywords = {viewed},
}

@incollection{battiti_new_2017,
	location = {Cham},
	title = {A New Local Search for the p-Center Problem Based on the Critical Vertex Concept},
	volume = {10556},
	isbn = {978-3-319-69403-0},
	url = {http://link.springer.com/10.1007/978-3-319-69404-7_6},
	abstract = {We propose a new smart local search for the p-center problem, based on the critical vertex concept, and embed it in a {GRASP} framework. Experimental results attest the robustness of the proposed search procedure and conﬁrm that for benchmark instances it converges to optimal or near/optimal solutions faster than the best known state-of-the-art local search.},
	pages = {79--92},
	booktitle = {Learning and Intelligent Optimization},
	publisher = {Springer International Publishing},
	author = {Ferone, Daniele and Festa, Paola and Napoletano, Antonio and Resende, Mauricio G. C.},
	editor = {Battiti, Roberto and Kvasov, Dmitri E. and Sergeyev, Yaroslav D.},
	urldate = {2021-02-14},
	date = {2017},
	langid = {english},
	doi = {10.1007/978-3-319-69404-7_6},
	note = {Series Title: Lecture Notes in Computer Science},
	file = {Ferone et al. - 2017 - A New Local Search for the p-Center Problem Based .pdf:C\:\\Users\\timch\\Zotero\\storage\\DSP4UTUF\\Ferone et al. - 2017 - A New Local Search for the p-Center Problem Based .pdf:application/pdf},
}

@article{feo_greedy_1995,
	title = {Greedy Randomized Adaptive Search Procedures},
	volume = {6},
	issn = {1573-2916},
	url = {https://doi.org/10.1007/BF01096763},
	doi = {10.1007/BF01096763},
	abstract = {Today, a variety of heuristic approaches are available to the operations research practitioner. One methodology that has a strong intuitive appeal, a prominent empirical track record, and is trivial to efficiently implement on parallel processors is {GRASP} (Greedy Randomized Adaptive Search Procedures). {GRASP} is an iterative randomized sampling technique in which each iteration provides a solution to the problem at hand. The incumbent solution over all {GRASP} iterations is kept as the final result. There are two phases within each {GRASP} iteration: the first intelligently constructs an initial solution via an adaptive randomized greedy function; the second applies a local search procedure to the constructed solution in hope of finding an improvement. In this paper, we define the various components comprising a {GRASP} and demonstrate, step by step, how to develop such heuristics for combinatorial optimization problems. Intuitive justifications for the observed empirical behavior of the methodology are discussed. The paper concludes with a brief literature review of {GRASP} implementations and mentions two industrial applications.},
	pages = {109--133},
	number = {2},
	journaltitle = {Journal of Global Optimization},
	shortjournal = {J Glob Optim},
	author = {Feo, Thomas A. and Resende, Mauricio G. C.},
	urldate = {2021-03-03},
	date = {1995-03-01},
	langid = {english},
	file = {Submitted Version:C\:\\Users\\timch\\Zotero\\storage\\78HSJCLC\\Feo and Resende - 1995 - Greedy Randomized Adaptive Search Procedures.pdf:application/pdf},
}

@article{al_nuaimi_applications_2015,
	title = {Applications of big data to smart cities},
	volume = {6},
	issn = {1869-0238},
	url = {https://doi.org/10.1186/s13174-015-0041-5},
	doi = {10.1186/s13174-015-0041-5},
	abstract = {Many governments are considering adopting the smart city concept in their cities and implementing big data applications that support smart city components to reach the required level of sustainability and improve the living standards. Smart cities utilize multiple technologies to improve the performance of health, transportation, energy, education, and water services leading to higher levels of comfort of their citizens. This involves reducing costs and resource consumption in addition to more effectively and actively engaging with their citizens. One of the recent technologies that has a huge potential to enhance smart city services is big data analytics. As digitization has become an integral part of everyday life, data collection has resulted in the accumulation of huge amounts of data that can be used in various beneficial application domains. Effective analysis and utilization of big data is a key factor for success in many business and service domains, including the smart city domain. This paper reviews the applications of big data to support smart cities. It discusses and compares different definitions of the smart city and big data and explores the opportunities, challenges and benefits of incorporating big data applications for smart cities. In addition it attempts to identify the requirements that support the implementation of big data applications for smart city services. The review reveals that several opportunities are available for utilizing big data in smart cities; however, there are still many issues and challenges to be addressed to achieve better utilization of this technology.},
	pages = {25},
	number = {1},
	journaltitle = {Journal of Internet Services and Applications},
	shortjournal = {Journal of Internet Services and Applications},
	author = {Al Nuaimi, Eiman and Al Neyadi, Hind and Mohamed, Nader and Al-Jaroodi, Jameela},
	urldate = {2021-03-06},
	date = {2015-12-01},
	keywords = {Application of big data, Application of smart city, Big data, Smart city},
	file = {Full Text PDF:C\:\\Users\\timch\\Zotero\\storage\\TVKSYTNM\\Al Nuaimi et al. - 2015 - Applications of big data to smart cities.pdf:application/pdf;Snapshot:C\:\\Users\\timch\\Zotero\\storage\\MX8DHVK2\\s13174-015-0041-5.html:text/html},
}

@article{hochbaum_best_1985,
	title = {A Best Possible Heuristic for the k-Center Problem},
	volume = {10},
	doi = {10.1287/moor.10.2.180},
	abstract = {In this paper we present a 2-approximation algorithm for the k-center problem with triangle inequality. This result is “best possible” since for any δ {\textless} 2 the existence of δ-approximation algorithm would imply that P = {NP}. It should be noted that no δ-approximation algorithm, for any constant δ, has been reported to date. Linear programming duality theory provides interesting insight to the problem and enables us to derive, in O{\textbar}E{\textbar} log {\textbar}E{\textbar} time, a solution with value no more than twice the k-center optimal value.

A by-product of the analysis is an O{\textbar}E{\textbar} algorithm that identifies a dominating set in G2, the square of a graph G, the size of which is no larger than the size of the minimum dominating set in the graph G. The key combinatorial object used is called a strong stable set, and we prove the {NP}-completeness of the corresponding decision problem.},
	pages = {180--184},
	journaltitle = {Mathematics of Operations Research - {MOR}},
	shortjournal = {Mathematics of Operations Research - {MOR}},
	author = {Hochbaum, Dorit and Shmoys, David},
	date = {1985-05-01},
	file = {Full Text PDF:C\:\\Users\\timch\\Zotero\\storage\\YPSKIS5G\\Hochbaum and Shmoys - 1985 - A Best Possible Heuristic for the k-Center Problem.pdf:application/pdf},
}

@article{mladenovic_solving_2003,
	title = {Solving the p-Center problem with Tabu Search and Variable Neighborhood Search},
	volume = {42},
	issn = {1097-0037},
	url = {http://onlinelibrary.wiley.com/doi/abs/10.1002/net.10081},
	doi = {10.1002/net.10081},
	abstract = {The p-Center problem consists of locating p facilities and assigning clients to them in order to minimize the maximum distance between a client and the facility to which he or she is allocated. In this paper, we present a basic Variable Neighborhood Search and two Tabu Search heuristics for the p-Center problem without the triangle inequality. Both proposed methods use the 1-interchange (or vertex substitution) neighborhood structure. We show how this neighborhood can be used even more efficiently than for solving the p-Median problem. Multistart 1-interchange, Variable Neighborhood Search, Tabu Search, and a few early heuristics are compared on small- and large-scale test problems from the literature. © 2003 Wiley Periodicals, Inc.},
	pages = {48--64},
	number = {1},
	journaltitle = {Networks},
	author = {Mladenović, Nenad and Labbé, Martine and Hansen, Pierre},
	urldate = {2020-10-23},
	date = {2003},
	langid = {english},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/net.10081},
	keywords = {unread, heuristics, location, variable neighborhood search, p-center, tabu search},
	file = {Full Text PDF:C\:\\Users\\timch\\Zotero\\storage\\GF3PYQF5\\Mladenović et al. - 2003 - Solving the p-Center problem with Tabu Search and .pdf:application/pdf;Snapshot:C\:\\Users\\timch\\Zotero\\storage\\VMSKL823\\net.html:text/html},
}

@article{hakimi_optimum_1965,
	title = {Optimum Distribution of Switching Centers in a Communication Network and Some Related Graph Theoretic Problems},
	volume = {13},
	issn = {0030-364X},
	url = {https://www.jstor.org/stable/167810},
	abstract = {The concept of a median in a weighted graph is generalized to a multimedian. Then, it is shown that the optimum distribution of p switching centers in a communication network is at a p-median of the corresponding weighted graph. The following related problem in highway networks is also considered: What is a minimum number of policemen that can be distributed in a highway network so that no one is farther away from a policeman than a given distance d? This problem is attacked by generating all vertex-coverings (externally stable sets) of a graph by means of a Boolean function defined over the vertices of a graph. Then this idea is extended to Boolean functions that generate all matchings, all factors, and all possible subgraphs of G with given degrees.},
	pages = {462--475},
	number = {3},
	journaltitle = {Operations Research},
	author = {Hakimi, S. L.},
	urldate = {2021-03-07},
	date = {1965},
	note = {Publisher: {INFORMS}},
	file = {JSTOR Full Text PDF:C\:\\Users\\timch\\Zotero\\storage\\YGIIXGE3\\Hakimi - 1965 - Optimum Distribution of Switching Centers in a Com.pdf:application/pdf},
}

@article{mladenovic_variable_1997,
	title = {Variable neighborhood search},
	volume = {24},
	issn = {0305-0548},
	url = {https://www.sciencedirect.com/science/article/pii/S0305054897000312},
	doi = {10.1016/S0305-0548(97)00031-2},
	abstract = {Systematic change of neighborhood within a local search algorithm yields a simple and effective metaheuristic for combinatorial optimization. We present a basic scheme for this purpose which can be implemented easily using any local search algorithm as a subroutine. Its effectiveness is illustrated by improvements in the {GENIUS} algorithm for the traveling salesman problem [1], without and with backhauls [2].},
	pages = {1097--1100},
	number = {11},
	journaltitle = {Computers \& Operations Research},
	shortjournal = {Computers \& Operations Research},
	author = {Mladenović, N. and Hansen, P.},
	urldate = {2021-03-14},
	date = {1997-11-01},
	langid = {english},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\timch\\Zotero\\storage\\RH8SRK9X\\Mladenović and Hansen - 1997 - Variable neighborhood search.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\timch\\Zotero\\storage\\T6MX2L44\\S0305054897000312.html:text/html},
}

@article{beasley_note_1985,
	title = {A note on solving large p-median problems},
	volume = {21},
	issn = {0377-2217},
	url = {https://www.sciencedirect.com/science/article/pii/0377221785900402},
	doi = {10.1016/0377-2217(85)90040-2},
	abstract = {In a previous paper we presented a tree search algorithm for the p-median problem, the problem of locating p facilities (medians) on a network, which was based upon La grangean relaxation and subgradient optimisation. That algorithm solved (optimally) problems with an arbitrary number of medians and having up to 200 vertices. In this note we show that it is possible to enhance that algorithm to solve (optimally) problems having up to 900 vertices using the Cray-1S computer.},
	pages = {270--273},
	number = {2},
	journaltitle = {European Journal of Operational Research},
	shortjournal = {European Journal of Operational Research},
	author = {Beasley, J. E.},
	urldate = {2021-03-16},
	date = {1985-08-01},
	langid = {english},
	keywords = {integer programming, Location, networks},
	file = {ScienceDirect Snapshot:C\:\\Users\\timch\\Zotero\\storage\\E6V97YJD\\0377221785900402.html:text/html},
}

@article{schwartz_efficient_2010,
	title = {An Efficient Implementation of the Robust k-Center Clustering Problem},
	abstract = {The standard k-center clustering problem is very sensitive to outliers. Charikar et al. proposed an alternative algorithm to cluster p points out of n total, thereby avoiding the distortion caused by outliers. The algorithm has an approximation bound of three times the true solution, but is very slow if implemented naively. We propose a modified implementation of the algorithm that runs significantly faster than the standard version. It does this while keeping the memory bound within the same asymptotic bound as that of the naive implementation. We show that, as the size of the problem increases, our algorithm maintains a relatively low running time, while the standard implementation time increases in proportion to it.},
	author = {Schwartz, Rachel},
	date = {2010-06-19},
}

@article{jia_fair_2020,
	title = {Fair Colorful k-Center Clustering},
	volume = {12125},
	url = {http://arxiv.org/abs/2007.04059},
	doi = {10.1007/978-3-030-45771-6_17},
	abstract = {An instance of colorful k-center consists of points in a metric space that are colored red or blue, along with an integer k and a coverage requirement for each color. The goal is to find the smallest radius {\textbackslash}r\{ho\} such that there exist balls of radius {\textbackslash}r\{ho\} around k of the points that meet the coverage requirements. The motivation behind this problem is twofold. First, from fairness considerations: each color/group should receive a similar service guarantee, and second, from the algorithmic challenges it poses: this problem combines the difficulties of clustering along with the subset-sum problem. In particular, we show that this combination results in strong integrality gap lower bounds for several natural linear programming relaxations. Our main result is an efficient approximation algorithm that overcomes these difficulties to achieve an approximation guarantee of 3, nearly matching the tight approximation guarantee of 2 for the classical k-center problem which this problem generalizes.},
	pages = {209--222},
	journaltitle = {{arXiv}:2007.04059 [cs]},
	author = {Jia, Xinrui and Sheth, Kshiteej and Svensson, Ola},
	urldate = {2020-10-10},
	date = {2020},
	eprinttype = {arxiv},
	eprint = {2007.04059},
	keywords = {viewed, Computer Science - Data Structures and Algorithms, F.2.2, high},
	file = {arXiv.org Snapshot:C\:\\Users\\timch\\Zotero\\storage\\ZAWX8GDJ\\2007.html:text/html;arXiv Fulltext PDF:C\:\\Users\\timch\\Zotero\\storage\\N4RMFICP\\Jia et al. - 2020 - Fair Colorful k-Center Clustering.pdf:application/pdf},
}